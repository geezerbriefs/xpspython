{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_full_hist (filepath):\n",
    "    \n",
    "    #full cc hist to update\n",
    "    full_cc_hist = pd.read_csv(filepath)\n",
    "    full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)\n",
    "    \n",
    "    return full_cc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase_file = [z for z in glob_list_of_cc_addenda if 'chase' in z][0]\n",
    "    \n",
    "    chase = pd.read_csv(chase_file)\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "                   #updated \"Trans Date\" to \"Transaction Date\" on 2019-03-05\n",
    "               .rename(columns = {'Transaction Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    ii = chase_clean['desc'].str.contains('AUTOMATIC PAYM')\n",
    "    chase_clean.loc[ii, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "#     min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, chase_file#, min_max_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "        #removed the addition of '-' to the Credits because the statements actually add the negative for me already\n",
    "        #as of 2019-03-05\n",
    "    df.loc[i, 'Debit'] = df.loc[i, 'Credit'].astype(str).apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].astype(str).apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citi_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'citi' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'discover' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and takes all new entries after the last recorded transaction in the history,\n",
    "    returning these as a df\n",
    "    \"\"\"\n",
    "    \n",
    "    #get this card's transactions\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    #get the date of the last recorded transaction on this card in the history\n",
    "    last_recorded_trans_date = max(full_cc_hist.loc[card_idx, 'date'])\n",
    "    \n",
    "\n",
    "    #get all downloaded transactions that happened AFTER the last recorded transaction date\n",
    "    #this assumed no retroactively applied transactions\n",
    "    eligible_new_trans = clean_new_entries.loc[clean_new_entries['date'] >= last_recorded_trans_date]\n",
    "    \n",
    "\n",
    "    #get the transactions from the full hist that occured on the last recorded date\n",
    "    #some of these may be repeated in the new entries, but some new entries may be new from that date\n",
    "    last_recorded_trans = full_cc_hist.loc[(full_cc_hist['date'] == last_recorded_trans_date) & card_idx]\n",
    "\n",
    "    #only possible overlaps here are ON the latest recorded transaction day, so put\n",
    "    #the new, and existing transactions from that day, together and remove duplicates\n",
    "    possible_overlap = pd.concat([eligible_new_trans, last_recorded_trans], sort=False)\n",
    "    \n",
    "\n",
    "    new_entries_idx = ~possible_overlap.duplicated(['date', 'price', 'card'], keep=False)\n",
    "    \n",
    "    #adding this block because a unique (not duplicated) last_recorded_trans will show up as a new transaction\n",
    "    #thanks to the concat step above followed by NOT dropping it again with the indexing below\n",
    "    #if it is not duplicated in the new entries, it is just ignored in the if part of this if/else\n",
    "    if all(new_entries_idx): #this means NONE of the eligible new transactions are duplicates of something in the last recorded transactions\n",
    "        new_entries = eligible_new_trans\n",
    "    else: #this means there were duplicates, both/all of which will be dropped\n",
    "        new_entries = possible_overlap.loc[new_entries_idx]\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_things_to_add (hist_files, full_cc_hist):\n",
    "    \n",
    "    #get the properly formatted chase transactions to be added and the date range they span\n",
    "    chase_clean, chase_file = get_chase_addendum(hist_files)\n",
    "    new_chase = find_new_entries (full_cc_hist, chase_clean, 'chase -8723')\n",
    "#     print('CHASE', new_chase)\n",
    "    \n",
    "    citi_clean, citi_file = get_citi_addendum(hist_files)\n",
    "    new_citi = find_new_entries (full_cc_hist, citi_clean, 'citi -6845')\n",
    "#     print('CITI', new_citi)\n",
    "    \n",
    "    disc_clean, disc_file = get_disc_addendum(hist_files)\n",
    "    new_disc = find_new_entries (full_cc_hist, disc_clean, 'discover -1362')\n",
    "#     print('DISC', new_disc)\n",
    "    \n",
    "    return pd.concat([new_chase, new_citi, new_disc], sort=False), [chase_file, citi_file, disc_file], [chase_clean, citi_clean, disc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_cc_hist (full_cc_hist, all_new_entries, file_dir, files_processed):\n",
    "    \n",
    "    new = (pd.concat([full_cc_hist, all_new_entries], sort=False)\n",
    "           .sort_values(by='date')\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    #this requires that the cc history is in the same place as the files with new entries and has the name\n",
    "    # 'cc_hist_tidy'\n",
    "    new.to_csv(file_dir + '/cc_hist_tidy' + '.csv', index=False)\n",
    "    \n",
    "    print(\"The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\")\n",
    "    print(\"You may now delete files {}\".format(files_processed))\n",
    "    print(\"they have been processed and added to the cc hist\")\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/geeze/Documents/finances/cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/geeze/Documents/finances/cc\\\\cc_hist_tidy.csv',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20190101_20190919_20190919.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\citi-Year to date.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\discover-2019-YearToDateSummary.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#are these the right files?\n",
    "hist_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = open_full_hist([z for z in hist_files if 'tidy' in z][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Patreon* Membership INTERNET GBR</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>85.82</td>\n",
       "      <td>FOUNDERS ALE HOUSE LOS ANGELES CA02048R</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>217.18</td>\n",
       "      <td>FOAM E-Z INC WESTMINSTER CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>25.00</td>\n",
       "      <td>THE STRONGHOLD CLIMBIN LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>54.41</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>24.08</td>\n",
       "      <td>VONS #3075 STH PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>32.23</td>\n",
       "      <td>CHEVRON 0308292</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>41.62</td>\n",
       "      <td>THE MENS WEARHOUSE #27 PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>22.22</td>\n",
       "      <td>VONS STORE 3075 SOUTH PASADENCA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Supermarkets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>76.64</td>\n",
       "      <td>THE MENS WEARHOUSE #27 PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>2019-07-28</td>\n",
       "      <td>3.00</td>\n",
       "      <td>UBER TECHNOLOGIES INC 8005928996 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   price                                     desc  \\\n",
       "939 2019-07-19    5.00         Patreon* Membership INTERNET GBR   \n",
       "940 2019-07-20   85.82  FOUNDERS ALE HOUSE LOS ANGELES CA02048R   \n",
       "941 2019-07-20  217.18              FOAM E-Z INC WESTMINSTER CA   \n",
       "942 2019-07-21   25.00    THE STRONGHOLD CLIMBIN LOS ANGELES CA   \n",
       "943 2019-07-21   54.41         THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "944 2019-07-22   24.08               VONS #3075 STH PASADENA CA   \n",
       "945 2019-07-22   32.23                          CHEVRON 0308292   \n",
       "946 2019-07-23   41.62       THE MENS WEARHOUSE #27 PASADENA CA   \n",
       "947 2019-07-25   22.22          VONS STORE 3075 SOUTH PASADENCA   \n",
       "948 2019-07-27   76.64       THE MENS WEARHOUSE #27 PASADENA CA   \n",
       "949 2019-07-28    3.00      UBER TECHNOLOGIES INC 8005928996 CA   \n",
       "\n",
       "               card           cat st close st open Category  \n",
       "939      citi -6845           NaN      NaN     NaN      NaN  \n",
       "940  discover -1362   Restaurants      NaN     NaN      NaN  \n",
       "941      citi -6845           NaN      NaN     NaN      NaN  \n",
       "942      citi -6845           NaN      NaN     NaN      NaN  \n",
       "943      citi -6845           NaN      NaN     NaN      NaN  \n",
       "944      citi -6845           NaN      NaN     NaN      NaN  \n",
       "945     chase -8723           NaN      NaN     NaN      Gas  \n",
       "946      citi -6845           NaN      NaN     NaN      NaN  \n",
       "947  discover -1362  Supermarkets      NaN     NaN      NaN  \n",
       "948      citi -6845           NaN      NaN     NaN      NaN  \n",
       "949      citi -6845           NaN      NaN     NaN      NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to cross reference against your cc hist sheet last entries\n",
    "full_cc_hist.loc[(max(full_cc_hist.index)-10) : max(full_cc_hist.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff, files_processed, cleaned_new_cc_info = all_things_to_add(hist_files, full_cc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff.to_csv(filepath + '/new_stuff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for card_cleaned in cleaned_new_cc_info:\n",
    "    card_cleaned.to_csv(filepath + '/{}.csv'.format(card_cleaned['card'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\n",
      "You may now delete files ['C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20190101_20190919_20190919.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\citi-Year to date.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\discover-2019-YearToDateSummary.csv']\n",
      "they have been processed and added to the cc hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>4.79</td>\n",
       "      <td>//USC Income (2,000/mo). Open date unknown</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2013</td>\n",
       "      <td>12/1/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>259.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2014</td>\n",
       "      <td>12/28/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>343.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2014</td>\n",
       "      <td>1/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>237.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2014</td>\n",
       "      <td>2/25/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>288.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/25/2014</td>\n",
       "      <td>3/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>182.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2014</td>\n",
       "      <td>4/26/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>475.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>5/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>326.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>6/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>346.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>164.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/26/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>307.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>9/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>265.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/26/2014</td>\n",
       "      <td>10/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>424.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/26/2014</td>\n",
       "      <td>11/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>492.27</td>\n",
       "      <td>(bought LIB)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2015</td>\n",
       "      <td>12/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>205.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2015</td>\n",
       "      <td>1/28/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>310.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>584.24</td>\n",
       "      <td>(bought kaplan)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>521.30</td>\n",
       "      <td>(bought Uworld)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>184.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>324.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>494.87</td>\n",
       "      <td>(bought maggy maid, was paid back by roomates)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>224.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>428.84</td>\n",
       "      <td>//Begin Caltech Income (2,666.67/mo)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>363.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>345.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>573.70</td>\n",
       "      <td>(also bought computer, but reimbursed 894.94)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>407.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>611.88</td>\n",
       "      <td>(bought LIB tix)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>864.00</td>\n",
       "      <td>(bought airline tix to PA and SEA)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>413.02</td>\n",
       "      <td>(bought stuff for SEA trip with grace)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>19.50</td>\n",
       "      <td>LAXSHUTTLETIX.COM ANAHEIM CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>24.16</td>\n",
       "      <td>76 - GSE 257503</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>96.36</td>\n",
       "      <td>SP * FIBERGLASS SOURCE 7148639826 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>-85.82</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>4.00</td>\n",
       "      <td>DUCK FOOT BREWING COMPAN SAN DIEGO CA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>46.55</td>\n",
       "      <td>SQ *WAYFARER BREAD LA JOLLA CA0001152921508733...</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>31.56</td>\n",
       "      <td>SQ *MAMA MUSUBI SOUTH PASADENCA000230584301240...</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>7.61</td>\n",
       "      <td>VONS #3075 STH PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>19.04</td>\n",
       "      <td>ALL AMERICAN FUEL OF PAG</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>17.70</td>\n",
       "      <td>SQ *MAMA MUSUBI IRVINE CA0001152921508754516005</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>32.91</td>\n",
       "      <td>CHEVRON 0308292</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>28.95</td>\n",
       "      <td>THE LINE LA FOOD &amp; BEVER LOS ANGELES CA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>4.33</td>\n",
       "      <td>eBay 800-456-3229 San Jose CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>3.84</td>\n",
       "      <td>eBay 800-456-3229 San Jose CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>39.99</td>\n",
       "      <td>PAYPAL *KENNETHROBE 4029357733 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>6.50</td>\n",
       "      <td>GOLDEN MILE</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>17.79</td>\n",
       "      <td>SUPER KING MARKET #3 ALTADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>8.53</td>\n",
       "      <td>Amazon.com*MO2UL8S41 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2019-09-04</td>\n",
       "      <td>7.99</td>\n",
       "      <td>BRISTOL FARMS # 02 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>-32.23</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>52.89</td>\n",
       "      <td>99 CENTS ONLY STORES # ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>-852.39</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>3.49</td>\n",
       "      <td>BRISTOL FARMS # 02 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2019-09-13</td>\n",
       "      <td>44.99</td>\n",
       "      <td>SPECTRUM 888-TWCABLE CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>5.81</td>\n",
       "      <td>AMAZON.COM*RC83Y5KH3 A AMZN.COM/BILL WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>31.52</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2019-09-15</td>\n",
       "      <td>18.00</td>\n",
       "      <td>582 GREAT CLIPS AT COS ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>10.50</td>\n",
       "      <td>AMZN Mktp US*US08L1FI3 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>6.69</td>\n",
       "      <td>AMZN Mktp US*B41BD7Q53 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>-301.52</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   price                                               desc  \\\n",
       "0   2013-12-01    4.79         //USC Income (2,000/mo). Open date unknown   \n",
       "1   2014-01-01  259.39                                                NaN   \n",
       "2   2014-02-01  343.67                                                NaN   \n",
       "3   2014-03-01  237.71                                                NaN   \n",
       "4   2014-04-01  288.67                                                NaN   \n",
       "5   2014-05-01  182.03                                                NaN   \n",
       "6   2014-06-01  475.33                                                NaN   \n",
       "7   2014-07-01  326.33                                                NaN   \n",
       "8   2014-08-01  346.95                                                NaN   \n",
       "9   2014-09-01  164.56                                                NaN   \n",
       "10  2014-10-01  307.70                                                NaN   \n",
       "11  2014-11-01  265.87                                                NaN   \n",
       "12  2014-12-01  424.86                                                NaN   \n",
       "13  2015-01-01  492.27                                       (bought LIB)   \n",
       "14  2015-02-01  205.33                                                NaN   \n",
       "15  2015-03-01  310.22                                                NaN   \n",
       "16  2015-04-01  584.24                                    (bought kaplan)   \n",
       "17  2015-05-01  521.30                                    (bought Uworld)   \n",
       "18  2015-06-01  184.77                                                NaN   \n",
       "19  2015-07-01  324.40                                                NaN   \n",
       "20  2015-08-01  494.87     (bought maggy maid, was paid back by roomates)   \n",
       "21  2015-09-01  224.18                                                NaN   \n",
       "22  2015-10-01  428.84               //Begin Caltech Income (2,666.67/mo)   \n",
       "23  2015-11-01  363.99                                                NaN   \n",
       "24  2015-12-01  345.70                                                NaN   \n",
       "25  2016-01-01  573.70      (also bought computer, but reimbursed 894.94)   \n",
       "26  2016-02-01  407.37                                                NaN   \n",
       "27  2016-03-01  611.88                                   (bought LIB tix)   \n",
       "28  2016-04-01  864.00                 (bought airline tix to PA and SEA)   \n",
       "29  2016-05-01  413.02             (bought stuff for SEA trip with grace)   \n",
       "..         ...     ...                                                ...   \n",
       "967 2019-08-12   19.50                       LAXSHUTTLETIX.COM ANAHEIM CA   \n",
       "968 2019-08-16   24.16                                    76 - GSE 257503   \n",
       "969 2019-08-16   96.36               SP * FIBERGLASS SOURCE 7148639826 CA   \n",
       "970 2019-08-17  -85.82                      AUTOMATIC PAYMENT - THANK YOU   \n",
       "971 2019-08-17    4.00              DUCK FOOT BREWING COMPAN SAN DIEGO CA   \n",
       "972 2019-08-18   46.55  SQ *WAYFARER BREAD LA JOLLA CA0001152921508733...   \n",
       "973 2019-08-22   31.56  SQ *MAMA MUSUBI SOUTH PASADENCA000230584301240...   \n",
       "974 2019-08-23    7.61                         VONS #3075 STH PASADENA CA   \n",
       "975 2019-08-24   19.04                           ALL AMERICAN FUEL OF PAG   \n",
       "976 2019-08-29   17.70    SQ *MAMA MUSUBI IRVINE CA0001152921508754516005   \n",
       "977 2019-08-31   32.91                                    CHEVRON 0308292   \n",
       "978 2019-09-02   28.95            THE LINE LA FOOD & BEVER LOS ANGELES CA   \n",
       "979 2019-09-02    4.33                      eBay 800-456-3229 San Jose CA   \n",
       "980 2019-09-02    3.84                      eBay 800-456-3229 San Jose CA   \n",
       "981 2019-09-02   39.99                  PAYPAL *KENNETHROBE 4029357733 CA   \n",
       "982 2019-09-02    6.50                                        GOLDEN MILE   \n",
       "983 2019-09-03   17.79                   SUPER KING MARKET #3 ALTADENA CA   \n",
       "984 2019-09-04    8.53              Amazon.com*MO2UL8S41 Amzn.com/bill WA   \n",
       "985 2019-09-04    7.99                BRISTOL FARMS # 02 SOUTH PASADEN CA   \n",
       "986 2019-09-05  -32.23                      AUTOMATIC PAYMENT - THANK YOU   \n",
       "987 2019-09-08   52.89                 99 CENTS ONLY STORES # ALHAMBRA CA   \n",
       "988 2019-09-12 -852.39                      AUTOMATIC PAYMENT - THANK YOU   \n",
       "989 2019-09-13    3.49                BRISTOL FARMS # 02 SOUTH PASADEN CA   \n",
       "990 2019-09-13   44.99                            SPECTRUM 888-TWCABLE CA   \n",
       "991 2019-09-15    5.81            AMAZON.COM*RC83Y5KH3 A AMZN.COM/BILL WA   \n",
       "992 2019-09-15   31.52                   THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "993 2019-09-15   18.00                 582 GREAT CLIPS AT COS ALHAMBRA CA   \n",
       "994 2019-09-16   10.50            AMZN Mktp US*US08L1FI3 Amzn.com/bill WA   \n",
       "995 2019-09-16    6.69            AMZN Mktp US*B41BD7Q53 Amzn.com/bill WA   \n",
       "996 2019-09-17 -301.52                      AUTOMATIC PAYMENT - THANK YOU   \n",
       "\n",
       "               card                   cat    st close     st open  \\\n",
       "0        amex -2002                   NaN  12/27/2013   12/1/2013   \n",
       "1        amex -2002                   NaN   1/27/2014  12/28/2013   \n",
       "2        amex -2002                   NaN   2/24/2014   1/28/2014   \n",
       "3        amex -2002                   NaN   3/27/2014   2/25/2014   \n",
       "4        amex -2002                   NaN   4/25/2014   3/28/2014   \n",
       "5        amex -2002                   NaN   5/27/2014   4/26/2014   \n",
       "6        amex -2002                   NaN   6/26/2014   5/28/2014   \n",
       "7        amex -2002                   NaN   7/27/2014   6/27/2014   \n",
       "8        amex -2002                   NaN   8/27/2014   7/28/2014   \n",
       "9        amex -2002                   NaN   9/26/2014   8/28/2014   \n",
       "10       amex -2002                   NaN  10/27/2014   9/27/2014   \n",
       "11       amex -2002                   NaN  11/26/2014  10/28/2014   \n",
       "12       amex -2002                   NaN  12/26/2014  11/27/2014   \n",
       "13       amex -2002                   NaN   1/27/2015  12/27/2014   \n",
       "14       amex -2002                   NaN   2/24/2015   1/28/2015   \n",
       "15       amex -2002                   NaN   3/27/2015   2/25/2015   \n",
       "16       amex -2002                   NaN   4/27/2015   3/27/2015   \n",
       "17       amex -2002                   NaN   5/27/2015   4/27/2015   \n",
       "18       amex -2002                   NaN   6/27/2015   5/27/2015   \n",
       "19       amex -2002                   NaN   7/27/2015   6/27/2015   \n",
       "20       amex -2002                   NaN   8/27/2015   7/27/2015   \n",
       "21       amex -2002                   NaN   9/27/2015   8/27/2015   \n",
       "22       amex -2002                   NaN  10/27/2015   9/27/2015   \n",
       "23       amex -2002                   NaN  11/27/2015  10/27/2015   \n",
       "24       amex -2002                   NaN  12/27/2015  11/27/2015   \n",
       "25       amex -2002                   NaN   1/27/2016  12/27/2015   \n",
       "26       amex -2002                   NaN   2/27/2016   1/27/2016   \n",
       "27       amex -2002                   NaN   3/27/2016   2/27/2016   \n",
       "28       amex -2002                   NaN   4/27/2016   3/27/2016   \n",
       "29       amex -2002                   NaN   5/27/2016   4/27/2016   \n",
       "..              ...                   ...         ...         ...   \n",
       "967      citi -6845                   NaN         NaN         NaN   \n",
       "968     chase -8723                   NaN         NaN         NaN   \n",
       "969      citi -6845                   NaN         NaN         NaN   \n",
       "970  discover -1362  Payments and Credits         NaN         NaN   \n",
       "971  discover -1362           Restaurants         NaN         NaN   \n",
       "972  discover -1362           Merchandise         NaN         NaN   \n",
       "973  discover -1362           Restaurants         NaN         NaN   \n",
       "974      citi -6845                   NaN         NaN         NaN   \n",
       "975     chase -8723                   NaN         NaN         NaN   \n",
       "976  discover -1362           Restaurants         NaN         NaN   \n",
       "977     chase -8723                   NaN         NaN         NaN   \n",
       "978  discover -1362           Restaurants         NaN         NaN   \n",
       "979      citi -6845                   NaN         NaN         NaN   \n",
       "980      citi -6845                   NaN         NaN         NaN   \n",
       "981      citi -6845                   NaN         NaN         NaN   \n",
       "982     chase -8723                   NaN         NaN         NaN   \n",
       "983      citi -6845                   NaN         NaN         NaN   \n",
       "984      citi -6845                   NaN         NaN         NaN   \n",
       "985      citi -6845                   NaN         NaN         NaN   \n",
       "986     chase -8723                   NaN         NaN         NaN   \n",
       "987      citi -6845                   NaN         NaN         NaN   \n",
       "988      citi -6845                   NaN         NaN         NaN   \n",
       "989      citi -6845                   NaN         NaN         NaN   \n",
       "990      citi -6845                   NaN         NaN         NaN   \n",
       "991      citi -6845                   NaN         NaN         NaN   \n",
       "992      citi -6845                   NaN         NaN         NaN   \n",
       "993      citi -6845                   NaN         NaN         NaN   \n",
       "994      citi -6845                   NaN         NaN         NaN   \n",
       "995      citi -6845                   NaN         NaN         NaN   \n",
       "996  discover -1362  Payments and Credits         NaN         NaN   \n",
       "\n",
       "          Category  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "5              NaN  \n",
       "6              NaN  \n",
       "7              NaN  \n",
       "8              NaN  \n",
       "9              NaN  \n",
       "10             NaN  \n",
       "11             NaN  \n",
       "12             NaN  \n",
       "13             NaN  \n",
       "14             NaN  \n",
       "15             NaN  \n",
       "16             NaN  \n",
       "17             NaN  \n",
       "18             NaN  \n",
       "19             NaN  \n",
       "20             NaN  \n",
       "21             NaN  \n",
       "22             NaN  \n",
       "23             NaN  \n",
       "24             NaN  \n",
       "25             NaN  \n",
       "26             NaN  \n",
       "27             NaN  \n",
       "28             NaN  \n",
       "29             NaN  \n",
       "..             ...  \n",
       "967            NaN  \n",
       "968            Gas  \n",
       "969            NaN  \n",
       "970            NaN  \n",
       "971            NaN  \n",
       "972            NaN  \n",
       "973            NaN  \n",
       "974            NaN  \n",
       "975            Gas  \n",
       "976            NaN  \n",
       "977            Gas  \n",
       "978            NaN  \n",
       "979            NaN  \n",
       "980            NaN  \n",
       "981            NaN  \n",
       "982  Entertainment  \n",
       "983            NaN  \n",
       "984            NaN  \n",
       "985            NaN  \n",
       "986            NaN  \n",
       "987            NaN  \n",
       "988            NaN  \n",
       "989            NaN  \n",
       "990            NaN  \n",
       "991            NaN  \n",
       "992            NaN  \n",
       "993            NaN  \n",
       "994            NaN  \n",
       "995            NaN  \n",
       "996            NaN  \n",
       "\n",
       "[997 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_new_cc_hist (full_cc_hist, new_stuff, filepath, files_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
