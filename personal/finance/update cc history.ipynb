{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_full_hist (filepath):\n",
    "    \n",
    "    #full cc hist to update\n",
    "    full_cc_hist = pd.read_csv(filepath)\n",
    "    full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)\n",
    "    \n",
    "    return full_cc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase_file = [z for z in glob_list_of_cc_addenda if 'chase' in z][0]\n",
    "    \n",
    "    chase = pd.read_csv(chase_file)\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "                   #updated \"Trans Date\" to \"Transaction Date\" on 2019-03-05\n",
    "               .rename(columns = {'Transaction Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    ii = chase_clean['desc'].str.contains('AUTOMATIC PAYM')\n",
    "    chase_clean.loc[ii, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "#     min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, chase_file#, min_max_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "        #removed the addition of '-' to the Credits because the statements actually add the negative for me already\n",
    "        #as of 2019-03-05\n",
    "    df.loc[i, 'Debit'] = df.loc[i, 'Credit'].astype(str).apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].astype(str).apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citi_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'citi' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'discover' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and takes all new entries after the last recorded transaction in the history,\n",
    "    returning these as a df\n",
    "    \"\"\"\n",
    "    \n",
    "    #get this card's transactions\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    #get the date of the last recorded transaction on this card in the history\n",
    "    last_recorded_trans_date = max(full_cc_hist.loc[card_idx, 'date'])\n",
    "    \n",
    "\n",
    "    #get all downloaded transactions that happened AFTER the last recorded transaction date\n",
    "    #this assumed no retroactively applied transactions\n",
    "    eligible_new_trans = clean_new_entries.loc[clean_new_entries['date'] >= last_recorded_trans_date]\n",
    "    \n",
    "\n",
    "    #get the transactions from the full hist that occured on the last recorded date\n",
    "    #some of these may be repeated in the new entries, but some new entries may be new from that date\n",
    "    last_recorded_trans = full_cc_hist.loc[(full_cc_hist['date'] == last_recorded_trans_date) & card_idx]\n",
    "\n",
    "    #only possible overlaps here are ON the latest recorded transaction day, so put\n",
    "    #the new, and existing transactions from that day, together and remove duplicates\n",
    "    possible_overlap = pd.concat([eligible_new_trans, last_recorded_trans], sort=False)\n",
    "    \n",
    "\n",
    "    new_entries_idx = ~possible_overlap.duplicated(['date', 'price', 'card'], keep=False)\n",
    "    \n",
    "    #adding this block because a unique (not duplicated) last_recorded_trans will show up as a new transaction\n",
    "    #thanks to the concat step above followed by NOT dropping it again with the indexing below\n",
    "    #if it is not duplicated in the new entries, it is just ignored in the if part of this if/else\n",
    "    if all(new_entries_idx): #this means NONE of the eligible new transactions are duplicates of something in the last recorded transactions\n",
    "        new_entries = eligible_new_trans\n",
    "    else: #this means there were duplicates, both/all of which will be dropped\n",
    "        new_entries = possible_overlap.loc[new_entries_idx]\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_things_to_add (hist_files, full_cc_hist):\n",
    "    \n",
    "    #get the properly formatted chase transactions to be added and the date range they span\n",
    "    chase_clean, chase_file = get_chase_addendum(hist_files)\n",
    "    new_chase = find_new_entries (full_cc_hist, chase_clean, 'chase -8723')\n",
    "#     print('CHASE', new_chase)\n",
    "    \n",
    "    citi_clean, citi_file = get_citi_addendum(hist_files)\n",
    "    new_citi = find_new_entries (full_cc_hist, citi_clean, 'citi -6845')\n",
    "#     print('CITI', new_citi)\n",
    "    \n",
    "    disc_clean, disc_file = get_disc_addendum(hist_files)\n",
    "    new_disc = find_new_entries (full_cc_hist, disc_clean, 'discover -1362')\n",
    "#     print('DISC', new_disc)\n",
    "    \n",
    "    return pd.concat([new_chase, new_citi, new_disc], sort=False), [chase_file, citi_file, disc_file], [chase_clean, citi_clean, disc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_cc_hist (full_cc_hist, all_new_entries, file_dir, files_processed):\n",
    "    \n",
    "    new = (pd.concat([full_cc_hist, all_new_entries], sort=False)\n",
    "           .sort_values(by='date')\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    #this requires that the cc history is in the same place as the files with new entries and has the name\n",
    "    # 'cc_hist_tidy'\n",
    "    new.to_csv(file_dir + '/cc_hist_tidy' + '.csv', index=False)\n",
    "    \n",
    "    print(\"The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\")\n",
    "    print(\"You may now delete files {}\".format(files_processed))\n",
    "    print(\"they have been processed and added to the cc hist\")\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/geeze/Documents/finances/cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/geeze/Documents/finances/cc\\\\cc_hist_tidy.csv',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20190101_20191231_20200102.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\citi_From 3_6_2019 To 1_2_2020.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\discover-Last12Months-20200102.csv']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#are these the right files?\n",
    "hist_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = open_full_hist([z for z in hist_files if 'tidy' in z][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>8.74</td>\n",
       "      <td>PARTY CITY 544</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2019-10-12</td>\n",
       "      <td>-223.98</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>2.30</td>\n",
       "      <td>PAYBYPHONE DIAMOND PAR SEATTLE WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>3.30</td>\n",
       "      <td>PAYBYPHONE DIAMOND PAR SEATTLE WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>44.99</td>\n",
       "      <td>SPECTRUM 855-707-7328 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>10.94</td>\n",
       "      <td>AMAZON.COM*LD1YL44C3 A AMZN.COM/BILL WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>4.10</td>\n",
       "      <td>PAYPAL *EBAY INC 4029357733 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>43.56</td>\n",
       "      <td>AMAZON.COM*V93KF1643 A AMZN.COM/BILL WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>39.99</td>\n",
       "      <td>PAYPAL *CAPRI UNL 4029357733 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>-113.04</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>2019-10-20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>LA CITY PARKING METER LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   price                                     desc  \\\n",
       "1012 2019-10-12    8.74                           PARTY CITY 544   \n",
       "1013 2019-10-12 -223.98            AUTOMATIC PAYMENT - THANK YOU   \n",
       "1014 2019-10-13    2.30        PAYBYPHONE DIAMOND PAR SEATTLE WA   \n",
       "1015 2019-10-13    3.30        PAYBYPHONE DIAMOND PAR SEATTLE WA   \n",
       "1016 2019-10-14   44.99                 SPECTRUM 855-707-7328 CA   \n",
       "1017 2019-10-14   10.94  AMAZON.COM*LD1YL44C3 A AMZN.COM/BILL WA   \n",
       "1018 2019-10-15    4.10           PAYPAL *EBAY INC 4029357733 CA   \n",
       "1019 2019-10-15   43.56  AMAZON.COM*V93KF1643 A AMZN.COM/BILL WA   \n",
       "1020 2019-10-15   39.99          PAYPAL *CAPRI UNL 4029357733 CA   \n",
       "1021 2019-10-17 -113.04            AUTOMATIC PAYMENT - THANK YOU   \n",
       "1022 2019-10-20    1.00     LA CITY PARKING METER LOS ANGELES CA   \n",
       "\n",
       "                card                   cat st close st open  Category  \n",
       "1012     chase -8723                   NaN      NaN     NaN  Shopping  \n",
       "1013      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1014      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1015      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1016      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1017      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1018      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1019      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1020      citi -6845                   NaN      NaN     NaN       NaN  \n",
       "1021  discover -1362  Payments and Credits      NaN     NaN       NaN  \n",
       "1022      citi -6845                   NaN      NaN     NaN       NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to cross reference against your cc hist sheet last entries\n",
    "full_cc_hist.loc[(max(full_cc_hist.index)-10) : max(full_cc_hist.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff, files_processed, cleaned_new_cc_info = all_things_to_add(hist_files, full_cc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff.to_csv(filepath + '/new_stuff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for card_cleaned in cleaned_new_cc_info:\n",
    "    card_cleaned.to_csv(filepath + '/{}.csv'.format(card_cleaned['card'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\n",
      "You may now delete files ['C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20190101_20191231_20200102.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\citi_From 3_6_2019 To 1_2_2020.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\discover-Last12Months-20200102.csv']\n",
      "they have been processed and added to the cc hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>4.79</td>\n",
       "      <td>//USC Income (2,000/mo). Open date unknown</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2013</td>\n",
       "      <td>12/1/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>259.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2014</td>\n",
       "      <td>12/28/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>343.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2014</td>\n",
       "      <td>1/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>237.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2014</td>\n",
       "      <td>2/25/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>288.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/25/2014</td>\n",
       "      <td>3/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>182.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2014</td>\n",
       "      <td>4/26/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>475.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>5/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>326.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>6/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>346.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>164.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/26/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>307.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>9/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>265.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/26/2014</td>\n",
       "      <td>10/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>424.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/26/2014</td>\n",
       "      <td>11/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>492.27</td>\n",
       "      <td>(bought LIB)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2015</td>\n",
       "      <td>12/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>205.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2015</td>\n",
       "      <td>1/28/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>310.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>584.24</td>\n",
       "      <td>(bought kaplan)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>521.30</td>\n",
       "      <td>(bought Uworld)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>184.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>324.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>494.87</td>\n",
       "      <td>(bought maggy maid, was paid back by roomates)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>224.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>428.84</td>\n",
       "      <td>//Begin Caltech Income (2,666.67/mo)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>363.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>345.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>573.70</td>\n",
       "      <td>(also bought computer, but reimbursed 894.94)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>407.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>611.88</td>\n",
       "      <td>(bought LIB tix)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>864.00</td>\n",
       "      <td>(bought airline tix to PA and SEA)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>413.02</td>\n",
       "      <td>(bought stuff for SEA trip with grace)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>2019-12-07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>LA CITY PARKING METER LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>2019-12-08</td>\n",
       "      <td>9.67</td>\n",
       "      <td>VONS #3075 STH PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>21.77</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>17.60</td>\n",
       "      <td>SHELL OIL 57445883507 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>SK175 STH PASADENA SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>ENTERPRISE RENT-A-CAR PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>11.43</td>\n",
       "      <td>AMAZON.COM*NR2JP3WL3 AMZN.COM/BILLWA6FOGV552DJK</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>51.45</td>\n",
       "      <td>AMZN MKTP US*HG3U99O83 AMZN.COM/BILLWA4F9TN0XZUEX</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>-1126.46</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>44.99</td>\n",
       "      <td>SPECTRUM 855-707-7328 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>10.92</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>-10.92</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>43.56</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>2019-12-15</td>\n",
       "      <td>11.46</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>29.43</td>\n",
       "      <td>CHEVRON 0092400 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>-81.50</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>26.00</td>\n",
       "      <td>SUPERCUTS - 858-259-08 SAN DIEGO CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>25.17</td>\n",
       "      <td>AMZN MKTP US*RP9EY6CI3 AMZN.COM/BILLWAZPOVBPH48YS</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>30.75</td>\n",
       "      <td>AMTRAK .3550746526756 8008727245 DC</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>1.75</td>\n",
       "      <td>LA METRO UNION STATQPS LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>5.26</td>\n",
       "      <td>AMZN MKTP US*XO95N5603 AMZN.COM/BILLWALA7FDM4ZJJD</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>3.64</td>\n",
       "      <td>CVS/PHARMACY #09668 PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>76.00</td>\n",
       "      <td>AMTRAK .3570721581493 8008727245 DC</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>15.88</td>\n",
       "      <td>UBER TECHNOLOGIES INC 8005928996 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>6.79</td>\n",
       "      <td>NINTENDO *AMERICAUS 800-255-3700 WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>89.72</td>\n",
       "      <td>AIRBNB HM4MJPKFJY 4158005959 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>28.64</td>\n",
       "      <td>CHEVRON 0211882 MILPITAS CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>28.81</td>\n",
       "      <td>CHEVRON 0308292 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>25.30</td>\n",
       "      <td>SANTA FE FOODS GONZALES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>70.18</td>\n",
       "      <td>DONA OAKLAND CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1095 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    price                                               desc  \\\n",
       "0    2013-12-01     4.79         //USC Income (2,000/mo). Open date unknown   \n",
       "1    2014-01-01   259.39                                                NaN   \n",
       "2    2014-02-01   343.67                                                NaN   \n",
       "3    2014-03-01   237.71                                                NaN   \n",
       "4    2014-04-01   288.67                                                NaN   \n",
       "5    2014-05-01   182.03                                                NaN   \n",
       "6    2014-06-01   475.33                                                NaN   \n",
       "7    2014-07-01   326.33                                                NaN   \n",
       "8    2014-08-01   346.95                                                NaN   \n",
       "9    2014-09-01   164.56                                                NaN   \n",
       "10   2014-10-01   307.70                                                NaN   \n",
       "11   2014-11-01   265.87                                                NaN   \n",
       "12   2014-12-01   424.86                                                NaN   \n",
       "13   2015-01-01   492.27                                       (bought LIB)   \n",
       "14   2015-02-01   205.33                                                NaN   \n",
       "15   2015-03-01   310.22                                                NaN   \n",
       "16   2015-04-01   584.24                                    (bought kaplan)   \n",
       "17   2015-05-01   521.30                                    (bought Uworld)   \n",
       "18   2015-06-01   184.77                                                NaN   \n",
       "19   2015-07-01   324.40                                                NaN   \n",
       "20   2015-08-01   494.87     (bought maggy maid, was paid back by roomates)   \n",
       "21   2015-09-01   224.18                                                NaN   \n",
       "22   2015-10-01   428.84               //Begin Caltech Income (2,666.67/mo)   \n",
       "23   2015-11-01   363.99                                                NaN   \n",
       "24   2015-12-01   345.70                                                NaN   \n",
       "25   2016-01-01   573.70      (also bought computer, but reimbursed 894.94)   \n",
       "26   2016-02-01   407.37                                                NaN   \n",
       "27   2016-03-01   611.88                                   (bought LIB tix)   \n",
       "28   2016-04-01   864.00                 (bought airline tix to PA and SEA)   \n",
       "29   2016-05-01   413.02             (bought stuff for SEA trip with grace)   \n",
       "...         ...      ...                                                ...   \n",
       "1065 2019-12-07     0.25               LA CITY PARKING METER LOS ANGELES CA   \n",
       "1066 2019-12-08     9.67                         VONS #3075 STH PASADENA CA   \n",
       "1067 2019-12-10    21.77                   THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1068 2019-12-11    17.60             SHELL OIL 57445883507 SOUTH PASADEN CA   \n",
       "1069 2019-12-11  1000.00                SK175 STH PASADENA SOUTH PASADEN CA   \n",
       "1070 2019-12-11  -100.00                  ENTERPRISE RENT-A-CAR PASADENA CA   \n",
       "1071 2019-12-11    11.43    AMAZON.COM*NR2JP3WL3 AMZN.COM/BILLWA6FOGV552DJK   \n",
       "1072 2019-12-11    51.45  AMZN MKTP US*HG3U99O83 AMZN.COM/BILLWA4F9TN0XZUEX   \n",
       "1073 2019-12-12 -1126.46                      AUTOMATIC PAYMENT - THANK YOU   \n",
       "1074 2019-12-14    44.99                           SPECTRUM 855-707-7328 CA   \n",
       "1075 2019-12-15    10.92                   THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1076 2019-12-15   -10.92                   THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1077 2019-12-15    43.56                      RALPHS #0021 SOUTH PASADEN CA   \n",
       "1078 2019-12-15    11.46                   THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1079 2019-12-16    29.43                        CHEVRON 0092400 ALHAMBRA CA   \n",
       "1080 2019-12-17   -81.50                      AUTOMATIC PAYMENT - THANK YOU   \n",
       "1081 2019-12-18    26.00                SUPERCUTS - 858-259-08 SAN DIEGO CA   \n",
       "1082 2019-12-21    25.17  AMZN MKTP US*RP9EY6CI3 AMZN.COM/BILLWAZPOVBPH48YS   \n",
       "1083 2019-12-21    30.75                AMTRAK .3550746526756 8008727245 DC   \n",
       "1084 2019-12-21     1.75              LA METRO UNION STATQPS LOS ANGELES CA   \n",
       "1085 2019-12-21     5.26  AMZN MKTP US*XO95N5603 AMZN.COM/BILLWALA7FDM4ZJJD   \n",
       "1086 2019-12-23     3.64                    CVS/PHARMACY #09668 PASADENA CA   \n",
       "1087 2019-12-23    76.00                AMTRAK .3570721581493 8008727245 DC   \n",
       "1088 2019-12-24    15.88                UBER TECHNOLOGIES INC 8005928996 CA   \n",
       "1089 2019-12-27     6.79                NINTENDO *AMERICAUS 800-255-3700 WA   \n",
       "1090 2019-12-27    89.72                    AIRBNB HM4MJPKFJY 4158005959 CA   \n",
       "1091 2019-12-29    28.64                        CHEVRON 0211882 MILPITAS CA   \n",
       "1092 2019-12-29    28.81                   CHEVRON 0308292 SOUTH PASADEN CA   \n",
       "1093 2019-12-29    25.30                         SANTA FE FOODS GONZALES CA   \n",
       "1094 2019-12-30    70.18                                    DONA OAKLAND CA   \n",
       "\n",
       "                card                   cat    st close     st open Category  \n",
       "0         amex -2002                   NaN  12/27/2013   12/1/2013      NaN  \n",
       "1         amex -2002                   NaN   1/27/2014  12/28/2013      NaN  \n",
       "2         amex -2002                   NaN   2/24/2014   1/28/2014      NaN  \n",
       "3         amex -2002                   NaN   3/27/2014   2/25/2014      NaN  \n",
       "4         amex -2002                   NaN   4/25/2014   3/28/2014      NaN  \n",
       "5         amex -2002                   NaN   5/27/2014   4/26/2014      NaN  \n",
       "6         amex -2002                   NaN   6/26/2014   5/28/2014      NaN  \n",
       "7         amex -2002                   NaN   7/27/2014   6/27/2014      NaN  \n",
       "8         amex -2002                   NaN   8/27/2014   7/28/2014      NaN  \n",
       "9         amex -2002                   NaN   9/26/2014   8/28/2014      NaN  \n",
       "10        amex -2002                   NaN  10/27/2014   9/27/2014      NaN  \n",
       "11        amex -2002                   NaN  11/26/2014  10/28/2014      NaN  \n",
       "12        amex -2002                   NaN  12/26/2014  11/27/2014      NaN  \n",
       "13        amex -2002                   NaN   1/27/2015  12/27/2014      NaN  \n",
       "14        amex -2002                   NaN   2/24/2015   1/28/2015      NaN  \n",
       "15        amex -2002                   NaN   3/27/2015   2/25/2015      NaN  \n",
       "16        amex -2002                   NaN   4/27/2015   3/27/2015      NaN  \n",
       "17        amex -2002                   NaN   5/27/2015   4/27/2015      NaN  \n",
       "18        amex -2002                   NaN   6/27/2015   5/27/2015      NaN  \n",
       "19        amex -2002                   NaN   7/27/2015   6/27/2015      NaN  \n",
       "20        amex -2002                   NaN   8/27/2015   7/27/2015      NaN  \n",
       "21        amex -2002                   NaN   9/27/2015   8/27/2015      NaN  \n",
       "22        amex -2002                   NaN  10/27/2015   9/27/2015      NaN  \n",
       "23        amex -2002                   NaN  11/27/2015  10/27/2015      NaN  \n",
       "24        amex -2002                   NaN  12/27/2015  11/27/2015      NaN  \n",
       "25        amex -2002                   NaN   1/27/2016  12/27/2015      NaN  \n",
       "26        amex -2002                   NaN   2/27/2016   1/27/2016      NaN  \n",
       "27        amex -2002                   NaN   3/27/2016   2/27/2016      NaN  \n",
       "28        amex -2002                   NaN   4/27/2016   3/27/2016      NaN  \n",
       "29        amex -2002                   NaN   5/27/2016   4/27/2016      NaN  \n",
       "...              ...                   ...         ...         ...      ...  \n",
       "1065      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1066      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1067      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1068      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1069      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1070      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1071  discover -1362           Merchandise         NaN         NaN      NaN  \n",
       "1072  discover -1362           Merchandise         NaN         NaN      NaN  \n",
       "1073      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1074      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1075      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1076      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1077      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1078      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1079      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1080  discover -1362  Payments and Credits         NaN         NaN      NaN  \n",
       "1081      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1082  discover -1362           Merchandise         NaN         NaN      NaN  \n",
       "1083      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1084      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1085  discover -1362           Merchandise         NaN         NaN      NaN  \n",
       "1086      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1087      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1088      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1089      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1090      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1091      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1092      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1093      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1094      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "\n",
       "[1095 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_new_cc_hist (full_cc_hist, new_stuff, filepath, files_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
