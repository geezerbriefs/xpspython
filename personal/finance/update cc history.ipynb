{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is the function you'll use to add an arbitrary cc table to your running cc history\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_full_hist (filepath):\n",
    "    \n",
    "    #full cc hist to update\n",
    "    full_cc_hist = pd.read_csv(filepath)\n",
    "    full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)\n",
    "    \n",
    "    return full_cc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase_file = [z for z in glob_list_of_cc_addenda if 'chase' in z][0]\n",
    "    \n",
    "    chase = pd.read_csv(chase_file)\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "               .rename(columns = {'Trans Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    ii = chase_clean['desc'].str.contains('AUTOMATIC PAYM')\n",
    "    chase_clean.loc[ii, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "#     min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, chase_file#, min_max_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "    df.loc[i, 'Debit'] = '-' + df.loc[i, 'Credit'].apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citi_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'citi' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'discover' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and takes all new entries after the last recorded transaction in the history,\n",
    "    returning these as a df\n",
    "    \"\"\"\n",
    "    \n",
    "    #get this card's transactions\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    #get the date of the last recorded transaction on this card in the history\n",
    "    last_recorded_trans_date = max(full_cc_hist.loc[card_idx, 'date'])\n",
    "\n",
    "    #get all downloaded transactions that happened AFTER the last recorded transaction date\n",
    "    #this assumed no retroactively applied transactions\n",
    "    eligible_new_trans = clean_new_entries.loc[clean_new_entries['date'] >= last_recorded_trans_date]\n",
    "\n",
    "    #get the transactions from the full hist that occured on the last recorded date\n",
    "    #some of these may be repeated in the new entries, but some new entries may be new from that date\n",
    "    last_recorded_trans = full_cc_hist.loc[full_cc_hist['date'] == last_recorded_trans_date]\n",
    "\n",
    "    #only possible overlaps here are ON the latest recorded transaction day, so put\n",
    "    #the new, and existing transactions from that day, together and remove duplicates\n",
    "    possible_overlap = pd.concat([eligible_new_trans, last_recorded_trans], sort=False)\n",
    "\n",
    "    new_entries_idx = ~possible_overlap.duplicated(['date', 'price', 'card'], keep=False)\n",
    "\n",
    "    new_entries = possible_overlap.loc[new_entries_idx]\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_things_to_add (hist_files, full_cc_hist):\n",
    "    \n",
    "    #get the properly formatted chase transactions to be added and the date range they span\n",
    "    chase_clean, chase_file = get_chase_addendum(hist_files)\n",
    "    new_chase = find_new_entries (full_cc_hist, chase_clean, 'chase -8723')\n",
    "    \n",
    "    citi_clean, citi_file = get_citi_addendum(hist_files)\n",
    "    new_citi = find_new_entries (full_cc_hist, citi_clean, 'citi -6845')\n",
    "    \n",
    "    disc_clean, disc_file = get_disc_addendum(hist_files)\n",
    "    new_disc = find_new_entries (full_cc_hist, disc_clean, 'discover -1362')\n",
    "    \n",
    "    return pd.concat([new_chase, new_citi, new_disc], sort=False), [chase_file, citi_file, disc_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_cc_hist (full_cc_hist, all_new_entries, file_dir, files_processed):\n",
    "    \n",
    "    new = (pd.concat([full_cc_hist, all_new_entries], sort=False)\n",
    "           .sort_values(by='date')\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    #this requires that the cc history is in the same place as the files with new entries and has the name\n",
    "    # 'cc_hist_tidy'\n",
    "    new.to_csv(file_dir + '/cc_hist_tidy' + '.csv', index=False)\n",
    "    \n",
    "    print(\"The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\")\n",
    "    print(\"You may now delete files {}\".format(files_processed))\n",
    "    print(\"they have been processed and added to the cc hist\")\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../../Finances/cc info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = open_full_hist([z for z in hist_files if 'tidy' in z][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff, files_processed = all_things_to_add(hist_files, full_cc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\n",
      "You may now delete files ['../../../Finances/cc info\\\\chase_20180813_to_20181116.CSV', '../../../Finances/cc info\\\\citi_YTD_until_20181124.CSV', '../../../Finances/cc info\\\\discover-YTD_until_20181124.csv']\n",
      "they have been processed and added to the cc hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>4.79</td>\n",
       "      <td>//USC Income (2,000/mo). Open date unknown</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2013</td>\n",
       "      <td>12/1/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>259.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2014</td>\n",
       "      <td>12/28/2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>343.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2014</td>\n",
       "      <td>1/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>237.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2014</td>\n",
       "      <td>2/25/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>288.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/25/2014</td>\n",
       "      <td>3/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>182.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2014</td>\n",
       "      <td>4/26/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>475.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>5/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>326.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>6/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>346.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>164.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/26/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>307.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>9/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>265.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/26/2014</td>\n",
       "      <td>10/28/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>424.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/26/2014</td>\n",
       "      <td>11/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>492.27</td>\n",
       "      <td>(bought LIB)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2015</td>\n",
       "      <td>12/27/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>205.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2015</td>\n",
       "      <td>1/28/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>310.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>2/25/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>584.24</td>\n",
       "      <td>(bought kaplan)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>3/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>521.30</td>\n",
       "      <td>(bought Uworld)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>4/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>184.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>5/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>324.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>6/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>494.87</td>\n",
       "      <td>(bought maggy maid, was paid back by roomates)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>7/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>224.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>8/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>428.84</td>\n",
       "      <td>//Begin Caltech Income (2,666.67/mo)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>9/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>363.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>10/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>345.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>11/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>573.70</td>\n",
       "      <td>(also bought computer, but reimbursed 894.94)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>12/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>407.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>1/27/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>611.88</td>\n",
       "      <td>(bought LIB tix)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>2/27/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>864.00</td>\n",
       "      <td>(bought airline tix to PA and SEA)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>3/27/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>413.02</td>\n",
       "      <td>(bought stuff for SEA trip with grace)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>4/27/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>14.95</td>\n",
       "      <td>AMZN Mktp US*MT8SC7KX2 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>9.99</td>\n",
       "      <td>AMZN Mktp US*MT4G647P0 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>21.85</td>\n",
       "      <td>Amazon.com*MT4AU8IP2   Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>1451.04</td>\n",
       "      <td>FIJI AIRWAYS           SYDNEY        AUS</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>15.32</td>\n",
       "      <td>Amazon.com*MT9H92I22   Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>-726.14</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>2018-10-12</td>\n",
       "      <td>2.07</td>\n",
       "      <td>CITY PARKING METERS    626-7446454   CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>15.87</td>\n",
       "      <td>MODAN ARTISANAL RAMEN  S PASADENA    CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2018-10-14</td>\n",
       "      <td>33.76</td>\n",
       "      <td>SHELL OIL 12357376008  PACIFIC PALIS CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>-403.01</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>31.27</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADENCA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Supermarkets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>60.00</td>\n",
       "      <td>CITY OF ALHAMBRA FINAN 626-5705007   CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>10.66</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADENCA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Supermarkets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>51.00</td>\n",
       "      <td>CITY CITATIONS &amp; PERMI 626-7444360   CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>2018-11-03</td>\n",
       "      <td>30.86</td>\n",
       "      <td>CHEVRON 0208458        BANNING       CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>-239.95</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>0.71</td>\n",
       "      <td>MAIL SERVICES          PASADENA      CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>1.25</td>\n",
       "      <td>CITY PASADENA</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>55.04</td>\n",
       "      <td>TIBET NEPAL HOUSE PASADENA CA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>2018-11-08</td>\n",
       "      <td>15.35</td>\n",
       "      <td>RALPHS #0021           SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>99.00</td>\n",
       "      <td>GROUPON INC            GROUPON.COM   IL</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NEON MONA              GLENDALE      CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>31.97</td>\n",
       "      <td>SHELL OIL 12481614001  ALHAMBRA      CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>2018-11-11</td>\n",
       "      <td>32.00</td>\n",
       "      <td>LEMONADE GLENDALE GLENDALE CA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>-1705.82</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>2.00</td>\n",
       "      <td>PKG PS 1-6, KEC, 9</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2018-11-17</td>\n",
       "      <td>-17.93</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2018-11-18</td>\n",
       "      <td>23.40</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADENCA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Supermarkets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>25.13</td>\n",
       "      <td>IMPERIAL WESTERN BEER  LOS ANGELES   CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>2018-11-20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>LA METRO FILLMORE SQPS PASADENA      CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>721 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    price                                            desc  \\\n",
       "0   2013-12-01     4.79      //USC Income (2,000/mo). Open date unknown   \n",
       "1   2014-01-01   259.39                                             NaN   \n",
       "2   2014-02-01   343.67                                             NaN   \n",
       "3   2014-03-01   237.71                                             NaN   \n",
       "4   2014-04-01   288.67                                             NaN   \n",
       "5   2014-05-01   182.03                                             NaN   \n",
       "6   2014-06-01   475.33                                             NaN   \n",
       "7   2014-07-01   326.33                                             NaN   \n",
       "8   2014-08-01   346.95                                             NaN   \n",
       "9   2014-09-01   164.56                                             NaN   \n",
       "10  2014-10-01   307.70                                             NaN   \n",
       "11  2014-11-01   265.87                                             NaN   \n",
       "12  2014-12-01   424.86                                             NaN   \n",
       "13  2015-01-01   492.27                                    (bought LIB)   \n",
       "14  2015-02-01   205.33                                             NaN   \n",
       "15  2015-03-01   310.22                                             NaN   \n",
       "16  2015-04-01   584.24                                 (bought kaplan)   \n",
       "17  2015-05-01   521.30                                 (bought Uworld)   \n",
       "18  2015-06-01   184.77                                             NaN   \n",
       "19  2015-07-01   324.40                                             NaN   \n",
       "20  2015-08-01   494.87  (bought maggy maid, was paid back by roomates)   \n",
       "21  2015-09-01   224.18                                             NaN   \n",
       "22  2015-10-01   428.84            //Begin Caltech Income (2,666.67/mo)   \n",
       "23  2015-11-01   363.99                                             NaN   \n",
       "24  2015-12-01   345.70                                             NaN   \n",
       "25  2016-01-01   573.70   (also bought computer, but reimbursed 894.94)   \n",
       "26  2016-02-01   407.37                                             NaN   \n",
       "27  2016-03-01   611.88                                (bought LIB tix)   \n",
       "28  2016-04-01   864.00              (bought airline tix to PA and SEA)   \n",
       "29  2016-05-01   413.02          (bought stuff for SEA trip with grace)   \n",
       "..         ...      ...                                             ...   \n",
       "691 2018-10-10    14.95        AMZN Mktp US*MT8SC7KX2 Amzn.com/bill WA    \n",
       "692 2018-10-10     9.99        AMZN Mktp US*MT4G647P0 Amzn.com/bill WA    \n",
       "693 2018-10-10    21.85        Amazon.com*MT4AU8IP2   Amzn.com/bill WA    \n",
       "694 2018-10-10  1451.04        FIJI AIRWAYS           SYDNEY        AUS   \n",
       "695 2018-10-11    15.32        Amazon.com*MT9H92I22   Amzn.com/bill WA    \n",
       "696 2018-10-12  -726.14                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "697 2018-10-12     2.07        CITY PARKING METERS    626-7446454   CA    \n",
       "698 2018-10-13    15.87        MODAN ARTISANAL RAMEN  S PASADENA    CA    \n",
       "699 2018-10-14    33.76        SHELL OIL 12357376008  PACIFIC PALIS CA    \n",
       "700 2018-10-17  -403.01                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "701 2018-10-25    31.27                    RALPHS #0021 SOUTH PASADENCA   \n",
       "702 2018-10-26    60.00         CITY OF ALHAMBRA FINAN 626-5705007   CA   \n",
       "703 2018-10-30    10.66                    RALPHS #0021 SOUTH PASADENCA   \n",
       "704 2018-11-02    51.00        CITY CITATIONS & PERMI 626-7444360   CA    \n",
       "705 2018-11-03    30.86        CHEVRON 0208458        BANNING       CA    \n",
       "706 2018-11-05  -239.95                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "707 2018-11-05     0.71        MAIL SERVICES          PASADENA      CA    \n",
       "708 2018-11-06     1.25                                   CITY PASADENA   \n",
       "709 2018-11-06    55.04                   TIBET NEPAL HOUSE PASADENA CA   \n",
       "710 2018-11-08    15.35        RALPHS #0021           SOUTH PASADEN CA    \n",
       "711 2018-11-10    99.00        GROUPON INC            GROUPON.COM   IL    \n",
       "712 2018-11-11    20.00        NEON MONA              GLENDALE      CA    \n",
       "713 2018-11-11    31.97        SHELL OIL 12481614001  ALHAMBRA      CA    \n",
       "714 2018-11-11    32.00                   LEMONADE GLENDALE GLENDALE CA   \n",
       "715 2018-11-12 -1705.82                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "716 2018-11-16     2.00                              PKG PS 1-6, KEC, 9   \n",
       "717 2018-11-17   -17.93                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "718 2018-11-18    23.40                    RALPHS #0021 SOUTH PASADENCA   \n",
       "719 2018-11-19    25.13         IMPERIAL WESTERN BEER  LOS ANGELES   CA   \n",
       "720 2018-11-20     1.75         LA METRO FILLMORE SQPS PASADENA      CA   \n",
       "\n",
       "               card                   cat    st close     st open  \n",
       "0        amex -2002                   NaN  12/27/2013   12/1/2013  \n",
       "1        amex -2002                   NaN   1/27/2014  12/28/2013  \n",
       "2        amex -2002                   NaN   2/24/2014   1/28/2014  \n",
       "3        amex -2002                   NaN   3/27/2014   2/25/2014  \n",
       "4        amex -2002                   NaN   4/25/2014   3/28/2014  \n",
       "5        amex -2002                   NaN   5/27/2014   4/26/2014  \n",
       "6        amex -2002                   NaN   6/26/2014   5/28/2014  \n",
       "7        amex -2002                   NaN   7/27/2014   6/27/2014  \n",
       "8        amex -2002                   NaN   8/27/2014   7/28/2014  \n",
       "9        amex -2002                   NaN   9/26/2014   8/28/2014  \n",
       "10       amex -2002                   NaN  10/27/2014   9/27/2014  \n",
       "11       amex -2002                   NaN  11/26/2014  10/28/2014  \n",
       "12       amex -2002                   NaN  12/26/2014  11/27/2014  \n",
       "13       amex -2002                   NaN   1/27/2015  12/27/2014  \n",
       "14       amex -2002                   NaN   2/24/2015   1/28/2015  \n",
       "15       amex -2002                   NaN   3/27/2015   2/25/2015  \n",
       "16       amex -2002                   NaN   4/27/2015   3/27/2015  \n",
       "17       amex -2002                   NaN   5/27/2015   4/27/2015  \n",
       "18       amex -2002                   NaN   6/27/2015   5/27/2015  \n",
       "19       amex -2002                   NaN   7/27/2015   6/27/2015  \n",
       "20       amex -2002                   NaN   8/27/2015   7/27/2015  \n",
       "21       amex -2002                   NaN   9/27/2015   8/27/2015  \n",
       "22       amex -2002                   NaN  10/27/2015   9/27/2015  \n",
       "23       amex -2002                   NaN  11/27/2015  10/27/2015  \n",
       "24       amex -2002                   NaN  12/27/2015  11/27/2015  \n",
       "25       amex -2002                   NaN   1/27/2016  12/27/2015  \n",
       "26       amex -2002                   NaN   2/27/2016   1/27/2016  \n",
       "27       amex -2002                   NaN   3/27/2016   2/27/2016  \n",
       "28       amex -2002                   NaN   4/27/2016   3/27/2016  \n",
       "29       amex -2002                   NaN   5/27/2016   4/27/2016  \n",
       "..              ...                   ...         ...         ...  \n",
       "691      citi -6845                   NaN         NaN         NaN  \n",
       "692      citi -6845                   NaN         NaN         NaN  \n",
       "693      citi -6845                   NaN         NaN         NaN  \n",
       "694      citi -6845                   NaN         NaN         NaN  \n",
       "695      citi -6845                   NaN         NaN         NaN  \n",
       "696      citi -6845                   NaN         NaN         NaN  \n",
       "697      citi -6845                   NaN         NaN         NaN  \n",
       "698      citi -6845                   NaN         NaN         NaN  \n",
       "699      citi -6845                   NaN         NaN         NaN  \n",
       "700  discover -1362  Payments and Credits         NaN         NaN  \n",
       "701  discover -1362          Supermarkets         NaN         NaN  \n",
       "702      citi -6845                   NaN         NaN         NaN  \n",
       "703  discover -1362          Supermarkets         NaN         NaN  \n",
       "704      citi -6845                   NaN         NaN         NaN  \n",
       "705      citi -6845                   NaN         NaN         NaN  \n",
       "706     chase -8723                   NaN         NaN         NaN  \n",
       "707      citi -6845                   NaN         NaN         NaN  \n",
       "708     chase -8723                   NaN         NaN         NaN  \n",
       "709  discover -1362           Restaurants         NaN         NaN  \n",
       "710      citi -6845                   NaN         NaN         NaN  \n",
       "711      citi -6845                   NaN         NaN         NaN  \n",
       "712      citi -6845                   NaN         NaN         NaN  \n",
       "713      citi -6845                   NaN         NaN         NaN  \n",
       "714  discover -1362           Restaurants         NaN         NaN  \n",
       "715      citi -6845                   NaN         NaN         NaN  \n",
       "716     chase -8723                   NaN         NaN         NaN  \n",
       "717  discover -1362  Payments and Credits         NaN         NaN  \n",
       "718  discover -1362          Supermarkets         NaN         NaN  \n",
       "719      citi -6845                   NaN         NaN         NaN  \n",
       "720      citi -6845                   NaN         NaN         NaN  \n",
       "\n",
       "[721 rows x 7 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_new_cc_hist (full_cc_hist, new_stuff, filepath, files_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
