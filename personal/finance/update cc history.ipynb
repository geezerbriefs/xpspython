{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis is the function you'll use to add an arbitrary cc table to your running cc history\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase = pd.read_csv([z for z in glob_list_of_cc_addenda if 'chase' in z][0])\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "               .rename(columns = {'Trans Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, min_max_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../../../Finances/cc info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = pd.read_csv([z for z in hist_files if 'tidy' in z][0])\n",
    "full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the properly formatted chase transactions to be added and the date range they span\n",
    "chase_clean, min_max_date_range = get_chase_addendum(hist_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, date_range, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and checks against existing transaction entries (within the date range spanned by new ones)\n",
    "    for duplicates, dropping them all and returning only verified new entries to append to cc hist\n",
    "    \"\"\"\n",
    "    \n",
    "    #select all the transactions already in the history for this card between the dates the addenda span\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    earlier_idx = full_cc_hist['date'] <= date_range[1]\n",
    "    later_idx = full_cc_hist['date'] >= date_range[0]\n",
    "    \n",
    "    #get the existing transactions in this date range\n",
    "    existing = full_cc_hist.loc[card_idx & earlier_idx & later_idx]\n",
    "    \n",
    "    #make a list of possible duplicate entries to check over\n",
    "    possible_duplis = pd.concat([existing, chase_clean], sort=False)\n",
    "    \n",
    "    #get idx of ALL duplicates in the concatendated df\n",
    "    dupli_idx = possible_duplis.duplicated(subset=['date', 'price', 'card'], keep=False)\n",
    "    \n",
    "    #create a df of just the duplicate entries (all of them)\n",
    "    duplicate_entries = possible_duplis.loc[dupli_idx]\n",
    "    \n",
    "    #drop all the duplicates from the list (by index, since new ones have fresh index from 0, old ones have high index)\n",
    "    new_entries = possible_duplis.drop(duplicate_entries.index)\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-16</td>\n",
       "      <td>2.00</td>\n",
       "      <td>PKG PS 1-6, KEC, 9</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>1.25</td>\n",
       "      <td>CITY PASADENA</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>-239.95</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   price                       desc         card  cat st close  \\\n",
       "0 2018-11-16    2.00         PKG PS 1-6, KEC, 9  chase -8723  NaN      NaN   \n",
       "1 2018-11-06    1.25              CITY PASADENA  chase -8723  NaN      NaN   \n",
       "2 2018-11-05 -239.95  AUTOMATIC PAYMENT - THANK  chase -8723  NaN      NaN   \n",
       "\n",
       "  st open  \n",
       "0     NaN  \n",
       "1     NaN  \n",
       "2     NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_new_entries (full_cc_hist, chase_clean, min_max_date_range, 'chase -8723')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think i did this a dumb way, the simple way to do this is to find the latest transaction date for the card, then find all new transactions that happened on or after that date, only check for duplicates on that overlapping day, and add the non duplicates and later transactions. that's way better and much less error prone. duh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
