{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chase statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_20 (string):\n",
    "    \"\"\"\n",
    "    makes 2 digit 2000's years ('17 or '10) into the 4 digit equivalent. If it's already 4 digit, leave it alone.\n",
    "    \n",
    "    Takes (string) which is the full date string of format mm/dd/yy or mm/dd/yyyy\n",
    "    \"\"\"\n",
    "    #check if it's a 2 digit year\n",
    "    if string[-3] == '/':\n",
    "        \n",
    "        return string[:-2] + '20' + string[-2:]\n",
    "    \n",
    "    #if it's already a 4 digit year, return as is\n",
    "    elif string[-3] == '0':\n",
    "        \n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_close (df_from_pdf):\n",
    "    \"\"\"\n",
    "    produces a list of series slices [opening datetime, closing datetime] by searching for the (hopefully)\n",
    "    single row where \"opening/closing date\" is listed, hopefully with the actual values as a separate cell\n",
    "    than \"opening/closing date\" string\n",
    "    ---Takes---\n",
    "    df_from_pdf : a whole pdf derived credit card statement as a dataframe\n",
    "    \n",
    "    ---Returns---\n",
    "    dates  :  [opening datetime, closing datetime] as series slices (I hope this is ok)\n",
    "    \"\"\"\n",
    "    \n",
    "    #copy so not mod orig\n",
    "    df = df_from_pdf.copy()\n",
    "    \n",
    "    #get just the actual data in the row with opening and closing date\n",
    "    df = df.dropna(axis=0, how='all').loc[df['Unnamed: 0'] == 'Opening/Closing Date', :].dropna(axis=1, how='all')\n",
    "    \n",
    "    #columns are default column titles that are annoying, rename to numbers\n",
    "    df.columns = [i for i in range(len(df.columns))]\n",
    "    \n",
    "    #df now has 2 columns [0] = 'opening/closing date', [1] = 'mm/dd/yy - mm/dd/yy'\n",
    "    open_close = df[1].str.split('-', expand=True)\n",
    "    \n",
    "    dates = []\n",
    "    for i in range(len(open_close.columns)):\n",
    "        dates.append(open_close[i].str.strip().apply(add_20).apply(get_dtime).values[0])\n",
    "    \n",
    "    #dates has open date first and close date second\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_date_string (entry):\n",
    "    \n",
    "    \"\"\"\n",
    "    decides whether or not a string matches the pattern 'mm/dd...'\n",
    "    just checks if that patterns is present at the beginning of the string, doesnt check for end of string\n",
    "    because statements sometimes have concatenated a bunch of strings into one giant entry that just begins\n",
    "    with mm/dd\n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(entry, str):\n",
    "    \n",
    "        bb = re.match(r\"([0-9]{1,2}?)/([0-9]{1,2}?)\", entry)\n",
    "\n",
    "        if bb:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_desc_price (row_of_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a row of a dataframe containing one transaction's information\n",
    "    the row must have at least 3 separate columns (others holding NaNs) with date, description, price\n",
    "    they must be in that order\n",
    "    \n",
    "    returns a dictionary with {'date':date, 'desc':description, 'price':price} for use in making dataframes later\n",
    "    \"\"\"\n",
    "    \n",
    "    #have to drop on index because a row slice is also a series object which doesn't have multiple columns\n",
    "    row = row_of_df.dropna(axis='index', how='all')\n",
    "    \n",
    "    #create tuples that pair date/desc/price to the appropriate item extracted from the row\n",
    "    #and make a dictionary where date/desc/price : appropriate data. This makes it easier to\n",
    "    #make dataframes later\n",
    "    date_desc_price_dict = {i:j for (i,j) in zip(['date', 'desc', 'price'], [item for item in row])}\n",
    "    \n",
    "\n",
    "    return date_desc_price_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_all_one_cell (df_row):\n",
    "    \"\"\"\n",
    "    if an entry has all the info smashed into the first ('date') cell in the excel sheet,\n",
    "    this function pulls out the date, desc and price and returns a dictionary that can be added\n",
    "    into the cleaned transaction dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    entry = df_row['date']\n",
    "    \n",
    "    sp = ' '\n",
    "    spaces = [pos for (pos, char) in enumerate(entry) if char == sp]\n",
    "    \n",
    "    first_space = spaces[0]\n",
    "    last_space = spaces[-1]\n",
    "    \n",
    "    date = entry[:first_space]\n",
    "    \n",
    "    try:\n",
    "        price = float(entry[last_space:])\n",
    "    except:\n",
    "        price = entry[last_space:]\n",
    "    \n",
    "    desc = entry[first_space:last_space].strip()\n",
    "    \n",
    "    \n",
    "    return {i:j for (i,j) in zip(['date', 'desc', 'price'], [date, desc, price])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_2_in_one (df_row):\n",
    "    \n",
    "    entry = df_row['date']\n",
    "    \n",
    "    sp = ' '\n",
    "    spaces = [pos for (pos, char) in enumerate(entry) if char == sp]\n",
    "    \n",
    "    first_space = spaces[0]\n",
    "    \n",
    "    date = df_row['date'][:first_space]\n",
    "    desc = df_row['date'][first_space:].strip()\n",
    "    price = df_row['desc']\n",
    "    \n",
    "    return {i:j for (i,j) in zip(['date', 'desc', 'price'], [date, desc, price])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_n_line (df):\n",
    "    \"\"\"\n",
    "    sometimes the first entry in the date column is concatenated with a newline ('\\n') and Purchases\n",
    "    This splits at the new line and takes just the date\n",
    "    \"\"\"\n",
    "    for row in df.index:\n",
    "    \n",
    "        entry = df.loc[row, 'date'] \n",
    "\n",
    "        if '\\n' in entry:\n",
    "            df.loc[row, 'date'] = entry.split('\\n')[0]\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_date_desc_price (raw_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes in a raw statement df read in from the xlsx file, searches using regex for dates of form 'mm/dd' in the\n",
    "    first column, then extracts just those rows, cleans them up, uses function date_desc_price() to attempt to\n",
    "    extract and label each piece of information appropriately and returns a dataframe with just the transaction\n",
    "    information. Because of variable formatting in the parent xlsx, there will be errors, which I clean up later.\n",
    "    \"\"\"\n",
    "    \n",
    "    #get the indices in the statement where the first columns entry is a date, which should identify only transaction rows\n",
    "    indx_where_trans = raw_df['Unnamed: 0'].apply(is_date_string)\n",
    "\n",
    "    #get these transactions as a slice with a fresh index and no junky NaNs\n",
    "    just_trans = (raw_df.loc[indx_where_trans, :]\n",
    "                  .dropna(axis='columns', how='all')\n",
    "                  .reset_index(drop=True)\n",
    "                 )\n",
    "\n",
    "    #make a list of dictionaries that hold all the date/desc/price info\n",
    "    trans_dicts=[]\n",
    "    for row in just_trans.index:\n",
    "\n",
    "        trans_dicts.append(date_desc_price(just_trans.loc[row]))\n",
    "        \n",
    "    #make a nice clean dataframe with the information you want\n",
    "    poss_err_trans = remove_n_line(pd.DataFrame(trans_dicts))\n",
    "    \n",
    "    return poss_err_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_squishing_errors (date_desc_price_df):\n",
    "    \"\"\"\n",
    "    there is variability in the parent xlsx documents that concatenates description and sometimes price to the date\n",
    "    column, this checks for these errors by looking for NaN's in the transactions dataframe and then doing the proper\n",
    "    correction based on the NaN pattern. The result is an dataframe with all the same transactions, but with concat\n",
    "    errors fixed. The index is out of order as a result of this, can easily sort to fix.\n",
    "    \"\"\"\n",
    "    \n",
    "    for index in date_desc_price_df.index:\n",
    "        \n",
    "        #get a single row, may have NaNs in fields that have been concatenated into fields to the left\n",
    "        h = date_desc_price_df.loc[index]\n",
    "\n",
    "        #NaN's aren't equal to each other so this test will check for them\n",
    "        #without triggering the weird np.isnan error when checking strings\n",
    "        test = [item==item for item in h]\n",
    "        \n",
    "        #complete row\n",
    "        if test == [True, True, True]:\n",
    "            pass\n",
    "        #date and desc squashed together, price is in desc\n",
    "        elif test == [True, True, False]:\n",
    "            date_desc_price_df = pd.concat([date_desc_price_df, pd.DataFrame(expand_2_in_one(h), index=[index])], axis='index')\n",
    "        #all are squashed in first column\n",
    "        elif test == [True, False, False] or test == [True]:\n",
    "            date_desc_price_df = pd.concat([date_desc_price_df, pd.DataFrame(expand_all_one_cell(h), index=[index])], axis='index')\n",
    "            \n",
    "    date_desc_price_df = date_desc_price_df.dropna(axis='index', how='any')\n",
    "    \n",
    "    return date_desc_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_YEN (trans_df):\n",
    "    \"\"\"\n",
    "    due to japan trip, there are some lines that have a date and the word \"YEN\" in them, but arent transactions\n",
    "    remove these\n",
    "    \"\"\"\n",
    "    \n",
    "    for row in trans_df.index:\n",
    "        #get a row\n",
    "        r = trans_df.loc[row]\n",
    "        \n",
    "        for x in r:\n",
    "            if 'YEN' in str(x):\n",
    "                trans_df = trans_df.drop(row, axis=0)\n",
    "    \n",
    "    return trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_trans_date (trans_df):\n",
    "    \"\"\"\n",
    "    transaction dates dont have years right now, sometimes transactions are from multiple years \n",
    "    (some are in 12/dd/2016, some are in 01/dd/2017). Add the proper year to the date column and\n",
    "    extract that date to datetime\n",
    "    \"\"\"\n",
    "    \n",
    "    #check if this statement spans the change of a year\n",
    "    c = trans_df.loc[0, 'st close'].year\n",
    "    o = trans_df.loc[0, 'st open'].year\n",
    "    \n",
    "    year_diff = c - o\n",
    "    \n",
    "    #the statement stays within the same year\n",
    "    if year_diff == 0:\n",
    "        #doesn't matter which year to append\n",
    "        trans_df['date'] = trans_df['date'] + '/' + str(c)\n",
    "        \n",
    "    #we change over years in this statement\n",
    "    elif year_diff == 1:\n",
    "        #where are the january transactions that should get the updated date\n",
    "        where = ['01/' in d for d in trans_df['date']]\n",
    "        \n",
    "        #replace the january transactions with the closing date's year, which should be advanced\n",
    "        trans_df.loc[where, 'date'] = trans_df.loc[where, 'date'] + '/' + str(c)\n",
    "        \n",
    "        #the one's that shouldn't get the advanced year\n",
    "        not_where = [not x for x in where]\n",
    "        \n",
    "        #add the not advanced year to these dates\n",
    "        trans_df.loc[not_where, 'date'] = trans_df.loc[not_where, 'date'] + '/' + str(o)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('this statement appears to span multiple years, that doesnt make sense')\n",
    "        \n",
    "    trans_df['date'] = trans_df['date'].apply(get_dtime)\n",
    "    \n",
    "    return trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_one_statement (filepath):\n",
    "    #open data\n",
    "    df = pd.read_excel(filepath)\n",
    "\n",
    "    #get the opening and closing dates as a list [open, close]\n",
    "    o_c = open_close(df)\n",
    "    \n",
    "    #get the cleaned up, but still error prone transctions df\n",
    "    poss_err_trans = extract_all_date_desc_price(df)\n",
    "    \n",
    "    #correct the concatenation errors\n",
    "    trans_clean = correct_squishing_errors(poss_err_trans)\n",
    "    \n",
    "    #add the statement association information\n",
    "    trans_clean['st open'] = o_c[0]\n",
    "    trans_clean['st close'] = o_c[1]\n",
    "    \n",
    "    #remove any lines that have \"YEN\" because they aren't transactions\n",
    "    trans_clean = remove_YEN(trans_clean)\n",
    "    \n",
    "    #complete and make datetime of the transaction date column\n",
    "    trans_clean = complete_trans_date(trans_clean)\n",
    "    \n",
    "    return trans_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sts_together (directory_with_st_xlsx):\n",
    "    \n",
    "    sts = glob.glob(directory_with_st_xlsx + '/*x8723-.xlsx')\n",
    "    \n",
    "    all_sts = []\n",
    "    for statement_xlsx in sts:\n",
    "        \n",
    "        all_sts.append(munge_one_statement(statement_xlsx))\n",
    "        \n",
    "    full_hist = pd.concat(all_sts, axis=0)\n",
    "    \n",
    "    return full_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../../Finances/cc info/chase(-8723) statements/csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geeze\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = all_sts_together(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#last statement was all buggy, so i just manually got the info out\n",
    "last = complete_trans_date(pd.read_excel('../../../Finances/cc info/chase(-8723) statements/csv/clean st 20181008.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put together\n",
    "full_hist = pd.concat([hist, last], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hist = full_hist.sort_values(by='date').reset_index(drop=True)\n",
    "full_hist['card'] = 'chase -8723'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>desc</th>\n",
       "      <th>price</th>\n",
       "      <th>st open</th>\n",
       "      <th>st close</th>\n",
       "      <th>card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-08-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-285.91</td>\n",
       "      <td>2016-07-09</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2016-09-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-1401.21</td>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>2016-09-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-333.94</td>\n",
       "      <td>2016-09-09</td>\n",
       "      <td>2016-10-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-999.56</td>\n",
       "      <td>2016-10-09</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-453.86</td>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-395.25</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-695.5</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-833.92</td>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>2017-03-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-967.29</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>2017-04-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-1126.64</td>\n",
       "      <td>2017-04-09</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-874.42</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-146.77</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>2017-07-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-77.85</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-130.52</td>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-168.48</td>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>2017-10-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-4.71</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>2018-02-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-36.07</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-503.55</td>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>2018-04-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-34.72</td>\n",
       "      <td>2018-04-09</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-13.32</td>\n",
       "      <td>2018-07-09</td>\n",
       "      <td>2018-08-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-26.78</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>2018-09-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>-43.9</td>\n",
       "      <td>2018-09-09</td>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>chase -8723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                           desc    price    st open   st close  \\\n",
       "28  2016-08-05  AUTOMATIC PAYMENT - THANK YOU  -285.91 2016-07-09 2016-08-08   \n",
       "46  2016-09-05  AUTOMATIC PAYMENT - THANK YOU -1401.21 2016-08-09 2016-09-08   \n",
       "70  2016-10-05  AUTOMATIC PAYMENT - THANK YOU  -333.94 2016-09-09 2016-10-08   \n",
       "88  2016-11-04  AUTOMATIC PAYMENT - THANK YOU  -999.56 2016-10-09 2016-11-08   \n",
       "107 2016-12-05  AUTOMATIC PAYMENT - THANK YOU  -453.86 2016-11-09 2016-12-08   \n",
       "141 2017-01-05  AUTOMATIC PAYMENT - THANK YOU  -395.25 2016-12-09 2017-01-08   \n",
       "164 2017-02-05  AUTOMATIC PAYMENT - THANK YOU   -695.5 2017-01-09 2017-02-08   \n",
       "183 2017-03-05  AUTOMATIC PAYMENT - THANK YOU  -833.92 2017-02-09 2017-03-08   \n",
       "210 2017-04-05  AUTOMATIC PAYMENT - THANK YOU  -967.29 2017-03-09 2017-04-08   \n",
       "224 2017-05-05  AUTOMATIC PAYMENT - THANK YOU -1126.64 2017-04-09 2017-05-08   \n",
       "231 2017-06-05  AUTOMATIC PAYMENT - THANK YOU  -874.42 2017-05-09 2017-06-08   \n",
       "235 2017-07-05  AUTOMATIC PAYMENT - THANK YOU  -146.77 2017-06-09 2017-07-08   \n",
       "242 2017-08-04  AUTOMATIC PAYMENT - THANK YOU   -77.85 2017-07-09 2017-08-08   \n",
       "254 2017-09-05  AUTOMATIC PAYMENT - THANK YOU  -130.52 2017-08-09 2017-09-08   \n",
       "261 2017-10-05  AUTOMATIC PAYMENT - THANK YOU  -168.48 2017-09-09 2017-10-08   \n",
       "265 2018-02-05  AUTOMATIC PAYMENT - THANK YOU    -4.71 2018-01-09 2018-02-08   \n",
       "277 2018-03-05  AUTOMATIC PAYMENT - THANK YOU   -36.07 2018-02-09 2018-03-08   \n",
       "280 2018-04-05  AUTOMATIC PAYMENT - THANK YOU  -503.55 2018-03-09 2018-04-08   \n",
       "281 2018-05-04  AUTOMATIC PAYMENT - THANK YOU   -34.72 2018-04-09 2018-05-08   \n",
       "292 2018-08-05  AUTOMATIC PAYMENT - THANK YOU   -13.32 2018-07-09 2018-08-08   \n",
       "296 2018-09-05  AUTOMATIC PAYMENT - THANK YOU   -26.78 2018-08-09 2018-09-08   \n",
       "302 2018-10-05  AUTOMATIC PAYMENT - THANK YOU    -43.9 2018-09-09 2018-10-08   \n",
       "\n",
       "            card  \n",
       "28   chase -8723  \n",
       "46   chase -8723  \n",
       "70   chase -8723  \n",
       "88   chase -8723  \n",
       "107  chase -8723  \n",
       "141  chase -8723  \n",
       "164  chase -8723  \n",
       "183  chase -8723  \n",
       "210  chase -8723  \n",
       "224  chase -8723  \n",
       "231  chase -8723  \n",
       "235  chase -8723  \n",
       "242  chase -8723  \n",
       "254  chase -8723  \n",
       "261  chase -8723  \n",
       "265  chase -8723  \n",
       "277  chase -8723  \n",
       "280  chase -8723  \n",
       "281  chase -8723  \n",
       "292  chase -8723  \n",
       "296  chase -8723  \n",
       "302  chase -8723  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_hist.loc[full_hist['desc'] == 'AUTOMATIC PAYMENT - THANK YOU', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hist.to_csv('../../../Finances/cc info/chase(-8723) statements/chase_up_to_20181008.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citi statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "    df.loc[i, 'Debit'] = '-' + df.loc[i, 'Credit'].apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_citi_hist (file):\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '../../../Finances/cc info/citi(-6845) history/*.csv'\n",
    "files = glob.glob(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hist = []\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    df_clean = munge_citi_hist(file)\n",
    "    \n",
    "    full_hist.append(df_clean)\n",
    "    \n",
    "citi_hist = pd.concat(full_hist, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "citi_hist.to_csv('../../../Finances/cc info/citi(-6845) history/citi_up_to_20181026.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_disc_hist (file):\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '../../../Finances/cc info/discover(-1362) statements/*Statement*.csv'\n",
    "files = glob.glob(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hist = []\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    df_clean = munge_disc_hist(file)\n",
    "    \n",
    "    full_hist.append(df_clean)\n",
    "    \n",
    "disc_hist = pd.concat(full_hist, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_hist.to_csv('../../../Finances/cc info/discover(-1362) statements/disc_up_to_20181002.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_approx_dates (df):\n",
    "    \n",
    "    for i in df.index:\n",
    "    \n",
    "        year = df.loc[i, 'st close'].year\n",
    "        mo = df.loc[i, 'st close'].month\n",
    "        #just make all transactions occur on the first of the month\n",
    "        #since majority of each statement period is in that month\n",
    "        day = '01'\n",
    "\n",
    "        df.loc[i, 'date'] = str(mo) + '/' + day + '/' + str(year)\n",
    "        \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.read_excel('../../../Finances/cc info/amex(-2002) history.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h.rename(columns = {'period' : 'date', 'notes' : 'desc', 'amnt' : 'price'})\n",
    "h['card'] = 'amex -2002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "h['st open'] = h['date'].str.split('-', expand=True)[0].str.replace(' ', '').apply(add_20).apply(get_dtime)\n",
    "\n",
    "h['st close'] = h['date'].str.split('-', expand=True)[1].str.replace(' ', '').apply(add_20).apply(get_dtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = make_approx_dates(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.to_csv('../../../Finances/cc info/amex(-2002)_TIDY.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all cc history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\geeze\\Documents\\Finances\\cc info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "citi = r'C:\\Users\\geeze\\Documents\\Finances\\cc info\\citi(-6845) history\\citi_up_to_20181026.csv'\n",
    "disc = r'C:\\Users\\geeze\\Documents\\Finances\\cc info\\discover(-1362) statements\\disc_up_to_20181002.csv'\n",
    "amex = r'C:\\Users\\geeze\\Documents\\Finances\\cc info\\amex(-2002)_TIDY.csv'\n",
    "chase = r'C:\\Users\\geeze\\Documents\\Finances\\cc info\\chase(-8723) statements\\chase_up_to_20181008.csv'\n",
    "\n",
    "ccs = [citi, disc, amex, chase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[           date                                      desc    price        card\n",
       " 0     4/21/2017  LA TRANSIT AVIATIONQPS LOS ANGELES   CA      1.75  citi -6845\n",
       " 1     4/23/2017  CHEVRON 0090199        ALHAMBRA      CA     25.33  citi -6845\n",
       " 2     4/27/2017  LA CITY PARKING METER  LOS ANGELES   CA      0.25  citi -6845\n",
       " 3     4/27/2017  LA CITY PARKING METER  LOS ANGELES   CA      6.00  citi -6845\n",
       " 4     4/27/2017  AMAZON MKTPLACE PMTS   AMZN.COM/BILL WA     31.75  citi -6845\n",
       " 5     4/29/2017  REO 0570-013-456       0570013456    GBR     5.60  citi -6845\n",
       " 6      5/4/2017  AMAZON MKTPLACE PMTS   AMZN.COM/BILL WA     72.97  citi -6845\n",
       " 7      5/6/2017  AMAZON MKTPLACE PMTS   AMZN.COM/BILL WA     72.97  citi -6845\n",
       " 8      5/8/2017  CHEVRON 0090199        ALHAMBRA      CA     29.08  citi -6845\n",
       " 9     5/11/2017  BLAZING STONE PIZZA    LOS ANGELES   CA     16.09  citi -6845\n",
       " 10    5/12/2017  MAGNOLIA HOUSE         PASADENA      CA    190.00  citi -6845\n",
       " 11    5/17/2017  MEMBERSHIP FEE MAY 17-APR 18                  NaN  citi -6845\n",
       " 12    5/17/2017  FOREIGN TRANSACTION FEE                      0.16  citi -6845\n",
       " 13    5/20/2017  MORLEY FIELD DISC GOLF CORONADO      CA      6.50  citi -6845\n",
       " 14    5/21/2017  AMAZON MKTPLACE PMTS   AMZN.COM/BILL WA    -72.97  citi -6845\n",
       " 15    5/24/2017  AMAZON MKTPLACE PMTS   AMZN.COM/BILL WA      8.59  citi -6845\n",
       " 16    5/26/2017  LA TRANSIT MISSION QPS SOUTH PASADEN CA      1.75  citi -6845\n",
       " 17    5/26/2017  MAIN TERM BURG20352001 ST PAUL       MN     10.77  citi -6845\n",
       " 18    5/27/2017  LAXSHUTTLETIX.COM      714-507-1165  CA      9.75  citi -6845\n",
       " 19    5/31/2017  LA TRANSIT UNION STQPS LOS ANGELES   CA      1.75  citi -6845\n",
       " 20    5/31/2017  LAXSHUTTLETIX.COM      714-507-1165  CA      9.75  citi -6845\n",
       " 21     6/5/2017  SP * CROSSINGS COFFEE  8588296113    CA     37.18  citi -6845\n",
       " 22     6/5/2017  AMTRAK .1560679111726  08008727245   DC     43.70  citi -6845\n",
       " 23     6/7/2017  CHEVRON 0090199        ALHAMBRA      CA     27.30  citi -6845\n",
       " 24     6/9/2017  CITY CITATIONS & PERMI 626-7444360   CA     48.00  citi -6845\n",
       " 25    6/11/2017  YOGURTLAND LITTLE TOKY LOS ANGELES   CA      4.41  citi -6845\n",
       " 26    6/11/2017  582 GREAT CLIPS AT COS ALHAMBRA      CA     10.99  citi -6845\n",
       " 27    6/12/2017             AUTOMATIC PAYMENT - THANK YOU  -378.98  citi -6845\n",
       " 28    6/12/2017  LA TRANSIT FILLMOREQPS PASADENA      CA      1.75  citi -6845\n",
       " 29    6/12/2017  LA TRANSIT LITTLE TQPS LOS ANGELES   CA      1.75  citi -6845\n",
       " ..          ...                                       ...      ...         ...\n",
       " 278   8/21/2018  AMZN Mktp US           Amzn.com/bill WA     32.08  citi -6845\n",
       " 279   8/22/2018  SUPER KING MARKET #3   ALTADENA      CA     21.20  citi -6845\n",
       " 280   8/24/2018  SEVEN GRAND LA         LOS ANGELES   CA      7.57  citi -6845\n",
       " 281   8/24/2018  JOES AUTO PARKS 812 S  LOS ANGELES   CA     12.00  citi -6845\n",
       " 282   8/25/2018  PIPES CAFE CARDIFF     CARDIFF BY TH CA      7.81  citi -6845\n",
       " 283   8/25/2018  CHEVRON 0353586        SAN DIEGO     CA     29.86  citi -6845\n",
       " 284   8/26/2018  SQ *SQ *WAYFARER BREAD La Jolla      CA      6.39  citi -6845\n",
       " 285   8/30/2018  CALTECH-JPL STORE      PASADENA      CA     43.69  citi -6845\n",
       " 286    9/4/2018  CALTECH-JPL STORE      PASADENA      CA    -21.84  citi -6845\n",
       " 287    9/5/2018  OLD PASADENA PARKING   PASADENA      CA      6.00  citi -6845\n",
       " 288    9/6/2018  SOUTHWES5261485505798  800-435-9792  TX    157.96  citi -6845\n",
       " 289    9/6/2018  SOUTHWES5261485509363  800-435-9792  TX    221.96  citi -6845\n",
       " 290   9/10/2018  CVS/PHARMACY #09500    VISALIA       CA     13.42  citi -6845\n",
       " 291   9/10/2018  SAVEMART#67 VISALIA    VISALIA       CA     41.41  citi -6845\n",
       " 292   9/12/2018             AUTOMATIC PAYMENT - THANK YOU  -430.04  citi -6845\n",
       " 293   9/20/2018  SQUARE      *SQ *HOT G Los Angeles   CA     25.18  citi -6845\n",
       " 294   9/20/2018  582 GREAT CLIPS AT COS ALHAMBRA      CA     18.00  citi -6845\n",
       " 295   9/24/2018  AUTOBAHN FUELS INC     LOS ANGELES   CA     30.66  citi -6845\n",
       " 296   10/5/2018  SHELL OIL 574427266QPS ENCINITAS     CA     27.13  citi -6845\n",
       " 297   10/7/2018  SQ *SQ *WAYFARER BREAD La Jolla      CA     40.00  citi -6845\n",
       " 298  10/10/2018  AMZN Mktp US*MT8SC7KX2 Amzn.com/bill WA     14.95  citi -6845\n",
       " 299  10/10/2018  AMZN Mktp US*MT4G647P0 Amzn.com/bill WA      9.99  citi -6845\n",
       " 300  10/10/2018  Amazon.com*MT4AU8IP2   Amzn.com/bill WA     21.85  citi -6845\n",
       " 301  10/10/2018  FIJI AIRWAYS           SYDNEY        AUS  1451.04  citi -6845\n",
       " 302  10/11/2018  Amazon.com*MT9H92I22   Amzn.com/bill WA     15.32  citi -6845\n",
       " 303  10/12/2018             AUTOMATIC PAYMENT - THANK YOU  -726.14  citi -6845\n",
       " 304  10/12/2018  CITY PARKING METERS    626-7446454   CA      2.07  citi -6845\n",
       " 305  10/13/2018  MODAN ARTISANAL RAMEN  S PASADENA    CA     15.87  citi -6845\n",
       " 306  10/14/2018  SHELL OIL 12357376008  PACIFIC PALIS CA     33.76  citi -6845\n",
       " 307  10/26/2018   CITY OF ALHAMBRA FINAN 626-5705007   CA    60.00  citi -6845\n",
       " \n",
       " [308 rows x 4 columns],\n",
       "           date                                               desc   price  \\\n",
       " 0    4/24/2018                       RALPHS #0021 SOUTH PASADENCA    1.99   \n",
       " 1    4/22/2018              SUPER KING MARKET #SSU LOS ANGELES CA   18.72   \n",
       " 2    4/20/2018                          CHIPOTLE 0233 REDLANDS CA    7.54   \n",
       " 3    4/20/2018                        VONS STORE 1734 REDLANDS CA   28.19   \n",
       " 4    4/20/2018                WAL-MART SC - #1915 YUCCA VALLEY CA    2.69   \n",
       " 5    4/19/2018                       RALPHS #0021 SOUTH PASADENCA   27.13   \n",
       " 6    4/18/2018                     FREETAXUSA.COM 801-812-1040 UT   12.95   \n",
       " 7     4/9/2018                       RALPHS #0021 SOUTH PASADENCA   18.65   \n",
       " 8     4/2/2018                     $50 STATEMENT CREDIT W 1ST PUR  -50.00   \n",
       " 9     4/1/2018                       RALPHS #0021 SOUTH PASADENCA   19.43   \n",
       " 10    4/1/2018                 SUPER KING MARKET #SSS ALTADENA CA   11.60   \n",
       " 11    4/1/2018                   THE HOME DEPOT #6610 ALHAMBRA CA   15.01   \n",
       " 12   5/23/2018                       RALPHS #0021 SOUTH PASADENCA    7.62   \n",
       " 13   5/20/2018                   SUPER KING MARKET #3 ALTADENA CA   18.74   \n",
       " 14   5/17/2018                      AUTOMATIC PAYMENT - THANK YOU -113.90   \n",
       " 15   5/16/2018                       RALPHS #0021 SOUTH PASADENCA   16.45   \n",
       " 16    5/9/2018                       RALPHS #0021 SOUTH PASADENCA    1.08   \n",
       " 17    5/8/2018                       RALPHS #0021 SOUTH PASADENCA   30.23   \n",
       " 18    5/3/2018             LA METRO MISSION STATI SOUTH PASADENCA    1.75   \n",
       " 19    5/2/2018                       RALPHS #0021 SOUTH PASADENCA    6.66   \n",
       " 20   6/17/2018                      AUTOMATIC PAYMENT - THANK YOU  -82.53   \n",
       " 21   6/12/2018                       RALPHS #0021 SOUTH PASADENCA    9.50   \n",
       " 22   6/10/2018                   SUPER KING MARKET #3 ALTADENA CA   29.72   \n",
       " 23    6/8/2018                        VONS STORE 1735 MOORPARK CA    8.88   \n",
       " 24    6/2/2018                  FRAZIER FARMS MARKET OCEANSIDE CA   10.30   \n",
       " 25    6/1/2018                     WHOLEFDS ARR 10237 PASADENA CA   12.25   \n",
       " 26   5/30/2018                       RALPHS #0021 SOUTH PASADENCA   30.65   \n",
       " 27   7/23/2018                       RALPHS #0021 SOUTH PASADENCA    9.38   \n",
       " 28   7/18/2018                       RALPHS #0021 SOUTH PASADENCA    9.32   \n",
       " 29   7/17/2018                      AUTOMATIC PAYMENT - THANK YOU -101.30   \n",
       " 30   7/15/2018                       RALPHS #0021 SOUTH PASADENCA    5.98   \n",
       " 31   7/11/2018                        SALADANG GARDEN PASADENA CA   19.62   \n",
       " 32    7/9/2018                       RALPHS #0021 SOUTH PASADENCA    8.96   \n",
       " 33    7/7/2018                   SUPER KING MARKET #3 ALTADENA CA   24.98   \n",
       " 34    7/6/2018                        SALADANG GARDEN PASADENA CA  148.74   \n",
       " 35   6/28/2018                       RALPHS #0021 SOUTH PASADENCA   35.58   \n",
       " 36   8/25/2018                   ALESMITH BREWING CO SAN DIEGO CA    6.00   \n",
       " 37   8/17/2018                      AUTOMATIC PAYMENT - THANK YOU -262.56   \n",
       " 38   8/10/2018                    DOG HAUS BIERGARDEN PASADENA CA   11.88   \n",
       " 39    8/5/2018             TENDER GREENS SANTA MO SANTA MONICA CA   29.56   \n",
       " 40    8/4/2018                      LEMONADE PASADENA PASADENA CA   14.14   \n",
       " 41    8/4/2018                 TST* WURSTK CHE - VENICE VENICE CA   25.49   \n",
       " 42   7/27/2018                      SHELL 12481614001 ALHAMBRA CA   29.47   \n",
       " 43   9/25/2018                       RALPHS #0021 SOUTH PASADENCA    9.47   \n",
       " 44   9/19/2018                   ABM WESTLAWN 2543 LOS ANGELES CA    8.00   \n",
       " 45   9/18/2018    SQ *PBJ.LA LOS ANGELES CA0001152921508222805112   11.50   \n",
       " 46   9/18/2018  SQ *STICKY RICE LOS ANGELES CA0001152921508222...   11.95   \n",
       " 47   9/17/2018                      AUTOMATIC PAYMENT - THANK YOU -116.54   \n",
       " 48   9/17/2018                       RALPHS #0021 SOUTH PASADENCA   14.85   \n",
       " 49    9/9/2018                      BROTZEIT LOKAL LLC OAKLAND CA   33.59   \n",
       " 50    9/9/2018  SQ *BURNT ENDS BBQ OAKLAND CA00011529215082101...   17.00   \n",
       " 51    9/8/2018                          DER WOLFSKOPF PASADENA CA    7.00   \n",
       " 52    9/8/2018                                     MUA OAKLAND CA   46.60   \n",
       " 53    9/7/2018                     LAZ PARKING 670512 PASADENA CA    6.00   \n",
       " 54    9/7/2018                        SALADANG GARDEN PASADENA CA  179.47   \n",
       " 55    9/6/2018                       RALPHS #0021 SOUTH PASADENCA   38.89   \n",
       " 56   8/28/2018                       RALPHS #0021 SOUTH PASADENCA   18.69   \n",
       " 57  10/17/2018                      AUTOMATIC PAYMENT - THANK YOU -403.01   \n",
       " 58   10/2/2018                       RALPHS #0021 SOUTH PASADENCA   17.93   \n",
       " \n",
       "                           cat            card  \n",
       " 0                Supermarkets  discover -1362  \n",
       " 1                Supermarkets  discover -1362  \n",
       " 2                 Restaurants  discover -1362  \n",
       " 3                Supermarkets  discover -1362  \n",
       " 4                 Merchandise  discover -1362  \n",
       " 5                Supermarkets  discover -1362  \n",
       " 6                    Services  discover -1362  \n",
       " 7                Supermarkets  discover -1362  \n",
       " 8   Awards and Rebate Credits  discover -1362  \n",
       " 9                Supermarkets  discover -1362  \n",
       " 10               Supermarkets  discover -1362  \n",
       " 11           Home Improvement  discover -1362  \n",
       " 12               Supermarkets  discover -1362  \n",
       " 13               Supermarkets  discover -1362  \n",
       " 14       Payments and Credits  discover -1362  \n",
       " 15               Supermarkets  discover -1362  \n",
       " 16               Supermarkets  discover -1362  \n",
       " 17               Supermarkets  discover -1362  \n",
       " 18      Travel/ Entertainment  discover -1362  \n",
       " 19               Supermarkets  discover -1362  \n",
       " 20       Payments and Credits  discover -1362  \n",
       " 21               Supermarkets  discover -1362  \n",
       " 22               Supermarkets  discover -1362  \n",
       " 23               Supermarkets  discover -1362  \n",
       " 24               Supermarkets  discover -1362  \n",
       " 25               Supermarkets  discover -1362  \n",
       " 26               Supermarkets  discover -1362  \n",
       " 27               Supermarkets  discover -1362  \n",
       " 28               Supermarkets  discover -1362  \n",
       " 29       Payments and Credits  discover -1362  \n",
       " 30               Supermarkets  discover -1362  \n",
       " 31                Restaurants  discover -1362  \n",
       " 32               Supermarkets  discover -1362  \n",
       " 33               Supermarkets  discover -1362  \n",
       " 34                Restaurants  discover -1362  \n",
       " 35               Supermarkets  discover -1362  \n",
       " 36                Restaurants  discover -1362  \n",
       " 37       Payments and Credits  discover -1362  \n",
       " 38                Restaurants  discover -1362  \n",
       " 39                Restaurants  discover -1362  \n",
       " 40                Restaurants  discover -1362  \n",
       " 41                Restaurants  discover -1362  \n",
       " 42                   Gasoline  discover -1362  \n",
       " 43               Supermarkets  discover -1362  \n",
       " 44                   Services  discover -1362  \n",
       " 45                Restaurants  discover -1362  \n",
       " 46                Restaurants  discover -1362  \n",
       " 47       Payments and Credits  discover -1362  \n",
       " 48               Supermarkets  discover -1362  \n",
       " 49                Restaurants  discover -1362  \n",
       " 50                Restaurants  discover -1362  \n",
       " 51                Restaurants  discover -1362  \n",
       " 52                Restaurants  discover -1362  \n",
       " 53                   Services  discover -1362  \n",
       " 54                Restaurants  discover -1362  \n",
       " 55               Supermarkets  discover -1362  \n",
       " 56               Supermarkets  discover -1362  \n",
       " 57       Payments and Credits  discover -1362  \n",
       " 58               Supermarkets  discover -1362  ,\n",
       "          date                                            desc   price  \\\n",
       " 0   12/1/2013      //USC Income (2,000/mo). Open date unknown    4.79   \n",
       " 1    1/1/2014                                             NaN  259.39   \n",
       " 2    2/1/2014                                             NaN  343.67   \n",
       " 3    3/1/2014                                             NaN  237.71   \n",
       " 4    4/1/2014                                             NaN  288.67   \n",
       " 5    5/1/2014                                             NaN  182.03   \n",
       " 6    6/1/2014                                             NaN  475.33   \n",
       " 7    7/1/2014                                             NaN  326.33   \n",
       " 8    8/1/2014                                             NaN  346.95   \n",
       " 9    9/1/2014                                             NaN  164.56   \n",
       " 10  10/1/2014                                             NaN  307.70   \n",
       " 11  11/1/2014                                             NaN  265.87   \n",
       " 12  12/1/2014                                             NaN  424.86   \n",
       " 13   1/1/2015                                    (bought LIB)  492.27   \n",
       " 14   2/1/2015                                             NaN  205.33   \n",
       " 15   3/1/2015                                             NaN  310.22   \n",
       " 16   4/1/2015                                 (bought kaplan)  584.24   \n",
       " 17   5/1/2015                                 (bought Uworld)  521.30   \n",
       " 18   6/1/2015                                             NaN  184.77   \n",
       " 19   7/1/2015                                             NaN  324.40   \n",
       " 20   8/1/2015  (bought maggy maid, was paid back by roomates)  494.87   \n",
       " 21   9/1/2015                                             NaN  224.18   \n",
       " 22  10/1/2015            //Begin Caltech Income (2,666.67/mo)  428.84   \n",
       " 23  11/1/2015                                             NaN  363.99   \n",
       " 24  12/1/2015                                             NaN  345.70   \n",
       " 25   1/1/2016   (also bought computer, but reimbursed 894.94)  573.70   \n",
       " 26   2/1/2016                                             NaN  407.37   \n",
       " 27   3/1/2016                                (bought LIB tix)  611.88   \n",
       " 28   4/1/2016              (bought airline tix to PA and SEA)  864.00   \n",
       " 29   5/1/2016          (bought stuff for SEA trip with grace)  413.02   \n",
       " \n",
       "           card     st open    st close  \n",
       " 0   amex -2002   12/1/2013  12/27/2013  \n",
       " 1   amex -2002  12/28/2013   1/27/2014  \n",
       " 2   amex -2002   1/28/2014   2/24/2014  \n",
       " 3   amex -2002   2/25/2014   3/27/2014  \n",
       " 4   amex -2002   3/28/2014   4/25/2014  \n",
       " 5   amex -2002   4/26/2014   5/27/2014  \n",
       " 6   amex -2002   5/28/2014   6/26/2014  \n",
       " 7   amex -2002   6/27/2014   7/27/2014  \n",
       " 8   amex -2002   7/28/2014   8/27/2014  \n",
       " 9   amex -2002   8/28/2014   9/26/2014  \n",
       " 10  amex -2002   9/27/2014  10/27/2014  \n",
       " 11  amex -2002  10/28/2014  11/26/2014  \n",
       " 12  amex -2002  11/27/2014  12/26/2014  \n",
       " 13  amex -2002  12/27/2014   1/27/2015  \n",
       " 14  amex -2002   1/28/2015   2/24/2015  \n",
       " 15  amex -2002   2/25/2015   3/27/2015  \n",
       " 16  amex -2002   3/27/2015   4/27/2015  \n",
       " 17  amex -2002   4/27/2015   5/27/2015  \n",
       " 18  amex -2002   5/27/2015   6/27/2015  \n",
       " 19  amex -2002   6/27/2015   7/27/2015  \n",
       " 20  amex -2002   7/27/2015   8/27/2015  \n",
       " 21  amex -2002   8/27/2015   9/27/2015  \n",
       " 22  amex -2002   9/27/2015  10/27/2015  \n",
       " 23  amex -2002  10/27/2015  11/27/2015  \n",
       " 24  amex -2002  11/27/2015  12/27/2015  \n",
       " 25  amex -2002  12/27/2015   1/27/2016  \n",
       " 26  amex -2002   1/27/2016   2/27/2016  \n",
       " 27  amex -2002   2/27/2016   3/27/2016  \n",
       " 28  amex -2002   3/27/2016   4/27/2016  \n",
       " 29  amex -2002   4/27/2016   5/27/2016  ,\n",
       "           date                                       desc   price   st open  \\\n",
       " 0    6/18/2016              THE CRAFTSMAN SANTA MONICA CA   28.08  6/9/2016   \n",
       " 1    6/23/2016          SOUND TRANSIT - SO QPS SEATTLE WA    6.00  6/9/2016   \n",
       " 2    6/23/2016     BIBBSY BEARS TEXAS BBQ PORT ANGELES WA   26.54  6/9/2016   \n",
       " 3    6/23/2016   ARAMARK LOG CABIN RESORT PORT ANGELES WA   81.70  6/9/2016   \n",
       " 4    6/24/2016       SQ *OPTIMISM BREWING COMP Seattle WA    8.00  6/9/2016   \n",
       " 5    6/24/2016         DYNW KLONDIKE GOLD RUSH SEATTLE WA   10.90  6/9/2016   \n",
       " 6    6/24/2016               SEATTLE STREETCAR SEATTLE WA    4.50  6/9/2016   \n",
       " 7    6/24/2016          SOUND TRANSIT - SO QPS SEATTLE WA    4.50  6/9/2016   \n",
       " 8    6/24/2016          ELYSIAN BREWING CO., I SEATTLE WA   51.00  6/9/2016   \n",
       " 9    6/27/2016              RALPHS #0021 SOUTH PASADEN CA   50.67  6/9/2016   \n",
       " 10    7/2/2016            CHEVRON 0203936 LAGUNA HILLS CA   23.79  6/9/2016   \n",
       " 11    7/6/2016              RALPHS #0021 SOUTH PASADEN CA   27.86  6/9/2016   \n",
       " 12    7/8/2016         PAVILIONS STOR00022244 PASADENA CA   13.04  7/9/2016   \n",
       " 13   7/12/2016                 AAA PASADENA-R PASADENA CA   36.35  7/9/2016   \n",
       " 14   7/13/2016              RALPHS #0021 SOUTH PASADEN CA   17.29  7/9/2016   \n",
       " 15   7/16/2016    DELTA AIR   0062113873630 ATLANTA, GEOR  203.86  7/9/2016   \n",
       " 16   7/16/2016       DELTA AIR   0062113045873 ATLANTA GA  166.40  7/9/2016   \n",
       " 17   7/18/2016                    FOREIGN TRANSACTION FEE    6.11  7/9/2016   \n",
       " 18   7/24/2016    DELTA AIR   0062143627772 ATLANTA, GEOR  -36.54  7/9/2016   \n",
       " 19   7/26/2016                    FOREIGN TRANSACTION FEE   -1.09  7/9/2016   \n",
       " 20   7/27/2016              RALPHS #0021 SOUTH PASADEN CA    3.68  7/9/2016   \n",
       " 21   7/27/2016              RALPHS #0021 SOUTH PASADEN CA   36.76  7/9/2016   \n",
       " 22   7/30/2016                CHEVRON 0090199 ALHAMBRA CA   20.73  7/9/2016   \n",
       " 23   7/31/2016   SPIRIT AIRL 4870133713178 800-7727117 FL  230.09  7/9/2016   \n",
       " 24    8/3/2016               FYF FESTIVAL 855-278-6345 CA  237.83  7/9/2016   \n",
       " 25    8/3/2016   SPIRIT AIRL 4870133932388 800-7727117 FL   80.00  7/9/2016   \n",
       " 26    8/5/2016                         ALDI 71080 YORK PA   19.39  7/9/2016   \n",
       " 27    8/5/2016                 SUPERCUTS PA 80444 YORK PA   18.95  7/9/2016   \n",
       " 28    8/5/2016              AUTOMATIC PAYMENT - THANK YOU -285.91  7/9/2016   \n",
       " 29    8/7/2016          BUDGET RENT-A-CAR PHILADELPHIA PA  209.23  7/9/2016   \n",
       " ..         ...                                        ...     ...       ...   \n",
       " 275  2/25/2018             SHELL OIL 10048330004 KIHEI HI   18.43  2/9/2018   \n",
       " 276  2/25/2018             SHELL OIL 10048330004 KIHEI HI    7.27  2/9/2018   \n",
       " 277   3/5/2018              AUTOMATIC PAYMENT - THANK YOU  -36.07  2/9/2018   \n",
       " 278  3/18/2018         UBER   *TRIP 5KD3D 800-592-8996 CA   11.85  3/9/2018   \n",
       " 279   4/1/2018             CHEVRON 0090851 LOS ANGELES CA   22.87  3/9/2018   \n",
       " 280   4/5/2018              AUTOMATIC PAYMENT - THANK YOU -503.55  3/9/2018   \n",
       " 281   5/4/2018              AUTOMATIC PAYMENT - THANK YOU  -34.72  4/9/2018   \n",
       " 282   5/4/2018         UBER   *TRIP 63VE7 800-592-8996 CA    4.03  4/9/2018   \n",
       " 283   5/4/2018         UBER   *TRIP ZOEXM 800-592-8996 CA   14.39  4/9/2018   \n",
       " 284   5/7/2018         UBER   *TRIP RDEGL 800-592-8996 CA    3.95  4/9/2018   \n",
       " 285   5/7/2018         UBER   *TRIP W2G32 800-592-8996 CA    3.92  4/9/2018   \n",
       " 286   7/6/2018         UBER   *TRIP QAB3H 800-592-8996 CA   13.32  6/9/2018   \n",
       " 287  7/14/2018     CITY OF LAGUNA BEACH I LAGUNA BEACH CA    4.50  7/9/2018   \n",
       " 288  7/15/2018  TST* LA SIRENA GRILL - DO LAGUNA BEACH CA   10.78  7/9/2018   \n",
       " 289  7/27/2018            JOE'S AUTO PARKS LOS ANGELES CA    3.00  7/9/2018   \n",
       " 290   8/2/2018            HOT 8 YOGA PASADENA PASADENA CA    3.00  7/9/2018   \n",
       " 291   8/5/2018     SM CITY PARKING METERS SANTA MONICA CA    2.50  7/9/2018   \n",
       " 292   8/5/2018              AUTOMATIC PAYMENT - THANK YOU  -13.32  7/9/2018   \n",
       " 293   8/7/2018            HOT 8 YOGA PASADENA PASADENA CA    3.00  7/9/2018   \n",
       " 294  8/13/2018              UCSD PARKING FLEX LA JOLLA CA    9.00  8/9/2018   \n",
       " 295   9/3/2018               OLD STONE STATION CAMBRIA CA   34.90  8/9/2018   \n",
       " 296   9/5/2018              AUTOMATIC PAYMENT - THANK YOU  -26.78  8/9/2018   \n",
       " 297   9/9/2018           NATURES BEST FOOD OAKLAND CA       87.16  9/9/2018   \n",
       " 298  9/10/2018       QUIK STOP #0071    Q80 MODESTO CA      44.84  9/9/2018   \n",
       " 299  9/14/2018    SHELL OIL 50404610029 BAKERSFIELD CA      61.93  9/9/2018   \n",
       " 300  9/23/2018         UBER   *TRIP LFREC 800-592-8996 CA   11.31  9/9/2018   \n",
       " 301  9/23/2018         UBER   *TRIP STFVH 800-592-8996 CA   21.41  9/9/2018   \n",
       " 302  10/5/2018              AUTOMATIC PAYMENT - THANK YOU  -43.90  9/9/2018   \n",
       " 303  10/6/2018         UBER   *TRIP KKAMO 800-592-8996 CA    6.65  9/9/2018   \n",
       " 304  10/6/2018         UBER   *TRIP ZAOML 800-592-8996 CA    6.65  9/9/2018   \n",
       " \n",
       "       st close         card  \n",
       " 0     7/8/2016  chase -8723  \n",
       " 1     7/8/2016  chase -8723  \n",
       " 2     7/8/2016  chase -8723  \n",
       " 3     7/8/2016  chase -8723  \n",
       " 4     7/8/2016  chase -8723  \n",
       " 5     7/8/2016  chase -8723  \n",
       " 6     7/8/2016  chase -8723  \n",
       " 7     7/8/2016  chase -8723  \n",
       " 8     7/8/2016  chase -8723  \n",
       " 9     7/8/2016  chase -8723  \n",
       " 10    7/8/2016  chase -8723  \n",
       " 11    7/8/2016  chase -8723  \n",
       " 12    8/8/2016  chase -8723  \n",
       " 13    8/8/2016  chase -8723  \n",
       " 14    8/8/2016  chase -8723  \n",
       " 15    8/8/2016  chase -8723  \n",
       " 16    8/8/2016  chase -8723  \n",
       " 17    8/8/2016  chase -8723  \n",
       " 18    8/8/2016  chase -8723  \n",
       " 19    8/8/2016  chase -8723  \n",
       " 20    8/8/2016  chase -8723  \n",
       " 21    8/8/2016  chase -8723  \n",
       " 22    8/8/2016  chase -8723  \n",
       " 23    8/8/2016  chase -8723  \n",
       " 24    8/8/2016  chase -8723  \n",
       " 25    8/8/2016  chase -8723  \n",
       " 26    8/8/2016  chase -8723  \n",
       " 27    8/8/2016  chase -8723  \n",
       " 28    8/8/2016  chase -8723  \n",
       " 29    8/8/2016  chase -8723  \n",
       " ..         ...          ...  \n",
       " 275   3/8/2018  chase -8723  \n",
       " 276   3/8/2018  chase -8723  \n",
       " 277   3/8/2018  chase -8723  \n",
       " 278   4/8/2018  chase -8723  \n",
       " 279   4/8/2018  chase -8723  \n",
       " 280   4/8/2018  chase -8723  \n",
       " 281   5/8/2018  chase -8723  \n",
       " 282   5/8/2018  chase -8723  \n",
       " 283   5/8/2018  chase -8723  \n",
       " 284   5/8/2018  chase -8723  \n",
       " 285   5/8/2018  chase -8723  \n",
       " 286   7/8/2018  chase -8723  \n",
       " 287   8/8/2018  chase -8723  \n",
       " 288   8/8/2018  chase -8723  \n",
       " 289   8/8/2018  chase -8723  \n",
       " 290   8/8/2018  chase -8723  \n",
       " 291   8/8/2018  chase -8723  \n",
       " 292   8/8/2018  chase -8723  \n",
       " 293   8/8/2018  chase -8723  \n",
       " 294   9/8/2018  chase -8723  \n",
       " 295   9/8/2018  chase -8723  \n",
       " 296   9/8/2018  chase -8723  \n",
       " 297  10/8/2018  chase -8723  \n",
       " 298  10/8/2018  chase -8723  \n",
       " 299  10/8/2018  chase -8723  \n",
       " 300  10/8/2018  chase -8723  \n",
       " 301  10/8/2018  chase -8723  \n",
       " 302  10/8/2018  chase -8723  \n",
       " 303  10/8/2018  chase -8723  \n",
       " 304  10/8/2018  chase -8723  \n",
       " \n",
       " [305 rows x 6 columns]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hists = []\n",
    "\n",
    "for cc in ccs:\n",
    "    hist = pd.read_csv(cc)\n",
    "    \n",
    "    hists.append(hist)\n",
    "    \n",
    "hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geeze\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "full_hist = pd.concat(hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_hist['date'] = full_hist['date'].apply(get_dtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_hist = (full_hist.reindex(columns = ['date', 'price', 'desc', 'card', 'cat', 'st close', 'st open'])\n",
    "             .sort_values(by='date')\n",
    "             .reset_index(drop=True)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = max(full_hist['date'])\n",
    "\n",
    "# full_hist.to_csv(r'C:\\Users\\geeze\\Documents\\Finances\\cc_hist_to_{}{}{}.csv'.format(last.year, last.month, last.day), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
