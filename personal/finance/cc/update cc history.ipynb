{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_full_hist (filepath):\n",
    "    \n",
    "    #full cc hist to update\n",
    "    full_cc_hist = pd.read_csv(filepath)\n",
    "    full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)\n",
    "    \n",
    "    return full_cc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase_file = [z for z in glob_list_of_cc_addenda if 'chase' in z][0]\n",
    "    \n",
    "    chase = pd.read_csv(chase_file)\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "                   #chase updated \"Trans Date\" to \"Transaction Date\" on 2019-03-05\n",
    "               .rename(columns = {'Transaction Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    ii = chase_clean['desc'].str.contains('AUTOMATIC PAYM')\n",
    "    chase_clean.loc[ii, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "#     min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, chase_file#, min_max_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "        #removed the addition of '-' to the Credits because the statements actually add the negative for me already\n",
    "        #as of 2019-03-05\n",
    "    df.loc[i, 'Debit'] = df.loc[i, 'Credit'].astype(str).apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].astype(str).apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citi_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'citi' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'discover' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and takes all new entries after the last recorded transaction in the history,\n",
    "    returning these as a df\n",
    "    \"\"\"\n",
    "    \n",
    "    #get this card's transactions\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    #get the date of the last recorded transaction on this card in the history\n",
    "    last_recorded_trans_date = max(full_cc_hist.loc[card_idx, 'date'])\n",
    "    \n",
    "\n",
    "    #get all downloaded transactions that happened AFTER the last recorded transaction date\n",
    "    #this assumed no retroactively applied transactions\n",
    "    eligible_new_trans = clean_new_entries.loc[clean_new_entries['date'] >= last_recorded_trans_date]\n",
    "    \n",
    "\n",
    "    #get the transactions from the full hist that occured on the last recorded date\n",
    "    #some of these may be repeated in the new entries, but some new entries may be new from that date\n",
    "    last_recorded_trans = full_cc_hist.loc[(full_cc_hist['date'] == last_recorded_trans_date) & card_idx]\n",
    "\n",
    "    #only possible overlaps here are ON the latest recorded transaction day, so put\n",
    "    #the new, and existing transactions from that day, together and remove duplicates\n",
    "    possible_overlap = pd.concat([eligible_new_trans, last_recorded_trans], sort=False)\n",
    "    \n",
    "\n",
    "    new_entries_idx = ~possible_overlap.duplicated(['date', 'price', 'card'], keep=False)\n",
    "    \n",
    "    #adding this block because a unique (not duplicated) last_recorded_trans will show up as a new transaction\n",
    "    #thanks to the concat step above followed by NOT dropping it again with the indexing below\n",
    "    #if it is not duplicated in the new entries, it is just ignored in the if part of this if/else\n",
    "    if all(new_entries_idx): #this means NONE of the eligible new transactions are duplicates of something in the last recorded transactions\n",
    "        new_entries = eligible_new_trans\n",
    "    else: #this means there were duplicates, both/all of which will be dropped\n",
    "        new_entries = possible_overlap.loc[new_entries_idx]\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_things_to_add (hist_files, full_cc_hist):\n",
    "    \n",
    "    #get the properly formatted chase transactions to be added and the date range they span\n",
    "    chase_clean, chase_file = get_chase_addendum(hist_files)\n",
    "    new_chase = find_new_entries (full_cc_hist, chase_clean, 'chase -8723')\n",
    "#     print('CHASE', new_chase)\n",
    "    \n",
    "    citi_clean, citi_file = get_citi_addendum(hist_files)\n",
    "    new_citi = find_new_entries (full_cc_hist, citi_clean, 'citi -6845')\n",
    "#     print('CITI', new_citi)\n",
    "    \n",
    "    disc_clean, disc_file = get_disc_addendum(hist_files)\n",
    "    new_disc = find_new_entries (full_cc_hist, disc_clean, 'discover -1362')\n",
    "#     print('DISC', new_disc)\n",
    "    \n",
    "    return pd.concat([new_chase, new_citi, new_disc], sort=False), [chase_file, citi_file, disc_file], [chase_clean, citi_clean, disc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_cc_hist (full_cc_hist, all_new_entries, file_dir, files_processed):\n",
    "    \n",
    "    new = (pd.concat([full_cc_hist, all_new_entries], sort=False)\n",
    "           .sort_values(by='date')\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    #this requires that the cc history is in the same place as the files with new entries and has the name\n",
    "    # 'cc_hist_tidy'\n",
    "    new.to_csv(file_dir + '/cc_hist_tidy' + '.csv', index=False)\n",
    "    \n",
    "    print(\"The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\")\n",
    "    print(\"You may now delete files {}\".format(files_processed))\n",
    "    print(\"they have been processed and added to the cc hist\")\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/geeze/Documents/finances/cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/geeze/Documents/finances/cc\\\\cc_hist_monthly.csv',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\cc_hist_tidy.csv',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20180802_20200802_20200802.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\citi YTD.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\discover-2020-YearToDateSummary.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#are these the right files?\n",
    "hist_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = open_full_hist([z for z in hist_files if 'tidy' in z][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>MEMBERSHIP FEE MAY 20-APR 21</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>3.52</td>\n",
       "      <td>MICHAELS #9490 800-642-4235 TX</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2020-05-22</td>\n",
       "      <td>18.70</td>\n",
       "      <td>PAVILION #2228 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>24.53</td>\n",
       "      <td>BLAZE PIZZA #1167-INT SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>2020-05-27</td>\n",
       "      <td>38.16</td>\n",
       "      <td>BLAZE PIZZA #1167-INT SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>8.78</td>\n",
       "      <td>AMAZON.COM*MY6VL8451 A AMZN.COM/BILL WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>27.52</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>12.43</td>\n",
       "      <td>EREPLACEMENTPARTS.COM 866-3229842 FL</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>31.69</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>9.42</td>\n",
       "      <td>99 CENTS ONLY STORES # ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>35.26</td>\n",
       "      <td>AMZN MKTP US*MY0G370V2 AMZN.COM/BILL WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  price                                     desc        card  \\\n",
       "1169 2020-05-19   0.00             MEMBERSHIP FEE MAY 20-APR 21  citi -6845   \n",
       "1170 2020-05-19   3.52           MICHAELS #9490 800-642-4235 TX  citi -6845   \n",
       "1171 2020-05-22  18.70          PAVILION #2228 SOUTH PASADEN CA  citi -6845   \n",
       "1172 2020-05-27  24.53   BLAZE PIZZA #1167-INT SOUTH PASADEN CA  citi -6845   \n",
       "1173 2020-05-27  38.16   BLAZE PIZZA #1167-INT SOUTH PASADEN CA  citi -6845   \n",
       "1174 2020-05-29   8.78  AMAZON.COM*MY6VL8451 A AMZN.COM/BILL WA  citi -6845   \n",
       "1175 2020-05-29  27.52            RALPHS #0021 SOUTH PASADEN CA  citi -6845   \n",
       "1176 2020-06-04  12.43     EREPLACEMENTPARTS.COM 866-3229842 FL  citi -6845   \n",
       "1177 2020-06-04  31.69         THE HOME DEPOT #6610 ALHAMBRA CA  citi -6845   \n",
       "1178 2020-06-06   9.42       99 CENTS ONLY STORES # ALHAMBRA CA  citi -6845   \n",
       "1179 2020-06-07  35.26  AMZN MKTP US*MY0G370V2 AMZN.COM/BILL WA  citi -6845   \n",
       "\n",
       "      cat st close st open Category  \n",
       "1169  NaN      NaN     NaN      NaN  \n",
       "1170  NaN      NaN     NaN      NaN  \n",
       "1171  NaN      NaN     NaN      NaN  \n",
       "1172  NaN      NaN     NaN      NaN  \n",
       "1173  NaN      NaN     NaN      NaN  \n",
       "1174  NaN      NaN     NaN      NaN  \n",
       "1175  NaN      NaN     NaN      NaN  \n",
       "1176  NaN      NaN     NaN      NaN  \n",
       "1177  NaN      NaN     NaN      NaN  \n",
       "1178  NaN      NaN     NaN      NaN  \n",
       "1179  NaN      NaN     NaN      NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to cross reference against your cc hist sheet last entries\n",
    "full_cc_hist.loc[(max(full_cc_hist.index)-10) : max(full_cc_hist.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff, files_processed, cleaned_new_cc_info = all_things_to_add(hist_files, full_cc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff.to_csv(filepath + '/new_stuff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP:\n",
    "## open the new_stuff.csv, your non-updated cc_hist_tidy, and each extended purchase history csv you just downloaded for each card\n",
    "\n",
    "## find the last entry in the cc_hist for each card, find this on the purchase history and determine what you expect to see for that card in the new_stuff. Is new_stuff correct? If so, you good, otherwise, diagnose and treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think this was here to assist with checking new_stuff but I have everything i need already done (see above)\n",
    "\n",
    "# for card_cleaned in cleaned_new_cc_info:\n",
    "#     card_cleaned.to_csv(filepath + '/{}.csv'.format(card_cleaned['card'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\n",
      "You may now delete files ['C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20180802_20200802_20200802.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\citi YTD.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\discover-2020-YearToDateSummary.csv']\n",
      "they have been processed and added to the cc hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>4.79</td>\n",
       "      <td>//USC Income (2,000/mo). Open date unknown</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2013</td>\n",
       "      <td>12/1/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>259.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2014</td>\n",
       "      <td>12/28/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>343.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2014</td>\n",
       "      <td>1/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>237.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2014</td>\n",
       "      <td>2/25/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>288.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/25/2014</td>\n",
       "      <td>3/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>2020-07-19</td>\n",
       "      <td>22.79</td>\n",
       "      <td>EXXONMOBIL 97260350 LEBEC CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>16.63</td>\n",
       "      <td>VONS #3075 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ALS AUTO SPA 2 LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>5.00</td>\n",
       "      <td>ALS AUTO SPA 2 LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>275.61</td>\n",
       "      <td>PAYPAL *EMBPHONESIN EB 4029357733 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   price                                        desc  \\\n",
       "0    2013-12-01    4.79  //USC Income (2,000/mo). Open date unknown   \n",
       "1    2014-01-01  259.39                                         NaN   \n",
       "2    2014-02-01  343.67                                         NaN   \n",
       "3    2014-03-01  237.71                                         NaN   \n",
       "4    2014-04-01  288.67                                         NaN   \n",
       "...         ...     ...                                         ...   \n",
       "1214 2020-07-19   22.79                EXXONMOBIL 97260350 LEBEC CA   \n",
       "1215 2020-07-22   16.63                 VONS #3075 SOUTH PASADEN CA   \n",
       "1216 2020-07-23    5.00               ALS AUTO SPA 2 LOS ANGELES CA   \n",
       "1217 2020-07-24    5.00               ALS AUTO SPA 2 LOS ANGELES CA   \n",
       "1218 2020-07-24  275.61        PAYPAL *EMBPHONESIN EB 4029357733 CA   \n",
       "\n",
       "            card  cat    st close     st open Category  \n",
       "0     amex -2002  NaN  12/27/2013   12/1/2013      NaN  \n",
       "1     amex -2002  NaN   1/27/2014  12/28/2013      NaN  \n",
       "2     amex -2002  NaN   2/24/2014   1/28/2014      NaN  \n",
       "3     amex -2002  NaN   3/27/2014   2/25/2014      NaN  \n",
       "4     amex -2002  NaN   4/25/2014   3/28/2014      NaN  \n",
       "...          ...  ...         ...         ...      ...  \n",
       "1214  citi -6845  NaN         NaN         NaN      NaN  \n",
       "1215  citi -6845  NaN         NaN         NaN      NaN  \n",
       "1216  citi -6845  NaN         NaN         NaN      NaN  \n",
       "1217  citi -6845  NaN         NaN         NaN      NaN  \n",
       "1218  citi -6845  NaN         NaN         NaN      NaN  \n",
       "\n",
       "[1219 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_new_cc_hist (full_cc_hist, new_stuff, filepath, files_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
