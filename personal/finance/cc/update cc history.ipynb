{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (date):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \n",
    "    if the value is already a datetime object, it just sends the datetime back\n",
    "    \"\"\"\n",
    "    if isinstance(date, str):\n",
    "        #doesn't account for pandas reading the string in a different format\n",
    "        return datetime.datetime.strptime(date, '%m/%d/%Y')\n",
    "    else:\n",
    "        return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_full_hist (filepath, sheet):\n",
    "    \n",
    "    #full cc hist to update\n",
    "    full_cc_hist = pd.read_excel(filepath, sheet_name=sheet)\n",
    "    full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)\n",
    "    \n",
    "    return full_cc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase_file = [z for z in glob_list_of_cc_addenda if 'chase' in z][0]\n",
    "    \n",
    "    chase = pd.read_csv(chase_file)\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "                   #chase updated \"Trans Date\" to \"Transaction Date\" on 2019-03-05\n",
    "               .rename(columns = {'Transaction Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    ii = chase_clean['desc'].str.contains('AUTOMATIC PAYM')\n",
    "    chase_clean.loc[ii, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "#     min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, chase_file#, min_max_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "        #removed the addition of '-' to the Credits because the statements actually add the negative for me already\n",
    "        #as of 2019-03-05\n",
    "    df.loc[i, 'Debit'] = df.loc[i, 'Credit'].astype(str).apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].astype(str).apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citi_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'citi' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'discover' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and takes all new entries after the last recorded transaction in the history,\n",
    "    returning these as a df\n",
    "    \"\"\"\n",
    "    \n",
    "    #get this card's transactions\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    #get the date of the last recorded transaction on this card in the history\n",
    "    last_recorded_trans_date = max(full_cc_hist.loc[card_idx, 'date'])\n",
    "    \n",
    "\n",
    "    #get all downloaded transactions that happened AFTER the last recorded transaction date\n",
    "    #this assumed no retroactively applied transactions\n",
    "    eligible_new_trans = clean_new_entries.loc[clean_new_entries['date'] >= last_recorded_trans_date]\n",
    "    \n",
    "\n",
    "    #get the transactions from the full hist that occured on the last recorded date\n",
    "    #some of these may be repeated in the new entries, but some new entries may be new from that date\n",
    "    last_recorded_trans = full_cc_hist.loc[(full_cc_hist['date'] == last_recorded_trans_date) & card_idx]\n",
    "\n",
    "    #only possible overlaps here are ON the latest recorded transaction day, so put\n",
    "    #the new, and existing transactions from that day, together and remove duplicates\n",
    "    possible_overlap = pd.concat([eligible_new_trans, last_recorded_trans], sort=False)\n",
    "    \n",
    "\n",
    "    new_entries_idx = ~possible_overlap.duplicated(['date', 'price', 'card'], keep=False)\n",
    "    \n",
    "    #adding this block because a unique (not duplicated) last_recorded_trans will show up as a new transaction\n",
    "    #thanks to the concat step above followed by NOT dropping it again with the indexing below\n",
    "    #if it is not duplicated in the new entries, it is just ignored in the if part of this if/else\n",
    "    if all(new_entries_idx): #this means NONE of the eligible new transactions are duplicates of something in the last recorded transactions\n",
    "        new_entries = eligible_new_trans\n",
    "    else: #this means there were duplicates, both/all of which will be dropped\n",
    "        new_entries = possible_overlap.loc[new_entries_idx]\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_things_to_add (hist_files, full_cc_hist):\n",
    "    \n",
    "    #get the properly formatted chase transactions to be added and the date range they span\n",
    "    chase_clean, chase_file = get_chase_addendum(hist_files)\n",
    "    new_chase = find_new_entries (full_cc_hist, chase_clean, 'chase -8723')\n",
    "#     print('CHASE', new_chase)\n",
    "    \n",
    "    citi_clean, citi_file = get_citi_addendum(hist_files)\n",
    "    new_citi = find_new_entries (full_cc_hist, citi_clean, 'citi -6845')\n",
    "#     print('CITI', new_citi)\n",
    "    \n",
    "    disc_clean, disc_file = get_disc_addendum(hist_files)\n",
    "    new_disc = find_new_entries (full_cc_hist, disc_clean, 'discover -1362')\n",
    "#     print('DISC', new_disc)\n",
    "    \n",
    "    return pd.concat([new_chase, new_citi, new_disc], sort=False), [chase_file, citi_file, disc_file], [chase_clean, citi_clean, disc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_autopay (hist):\n",
    "    \n",
    "    autopays = hist.loc[hist['desc'].str.contains('AUTOMATIC PAYMENT').fillna(False)].index\n",
    "    \n",
    "    hist = hist.loc[[u for u in hist.index if u not in autopays], :]\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_cc_hist (full_cc_hist, all_new_entries, file_dir, files_processed):\n",
    "    \n",
    "    new = (pd.concat([full_cc_hist, all_new_entries], sort=False)\n",
    "           .sort_values(by='date')\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "     \n",
    "    #write to the cc_mstr_hist workbook\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    path = file_dir + '/cc_mstr_hist' + '.xlsx'\n",
    "\n",
    "    book = load_workbook(path)\n",
    "    writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "    writer.book = book\n",
    "\n",
    "    new.to_excel(writer, sheet_name = 'cc_hist_tidy', index=False)\n",
    "    \n",
    "    \n",
    "    #now save the history binned monthly, remove autopays so it's just monthly outflow from credit cards\n",
    "    new_no_autopay = drop_autopay(new)\n",
    "    \n",
    "    monthly = new_no_autopay.resample('M', on='date').sum()\n",
    "    \n",
    "    monthly.reset_index().drop('Memo', axis='columns').to_excel(writer, sheet_name = 'cc_hist_monthly', index=False)\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "    \n",
    "    print(\"The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\")\n",
    "    print(\"You may now delete files {}\".format(files_processed))\n",
    "    print(\"they have been processed and added to the cc hist\")\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/geeze/Documents/finances/cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/geeze/Documents/finances/cc\\\\chase_2020YTD.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\citi_2020Year to date.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\discover-2020-YearToDateSummary.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#are these the right files?\n",
    "hist_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = open_full_hist(filepath + '/cc_mstr_hist.xlsx', 'cc_hist_tidy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2020-09-18</td>\n",
       "      <td>119.65</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2020-09-21</td>\n",
       "      <td>8.97</td>\n",
       "      <td>VONS #3075 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>643.44</td>\n",
       "      <td>PAYPAL *ACERRECER EBAY 888-221-1161 CA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>44.09</td>\n",
       "      <td>NAKEDWINES.COM INC NAPA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>36.85</td>\n",
       "      <td>WIPERBLADESUSA.COM HILLSBORO OR</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2020-09-24</td>\n",
       "      <td>12.46</td>\n",
       "      <td>eBay O*12-05780-94016 San Jose CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>13.48</td>\n",
       "      <td>BRISTOL FARMS # 02 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>27.14</td>\n",
       "      <td>CHEVRON 0308292 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>6.07</td>\n",
       "      <td>VONS #3075 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>7.49</td>\n",
       "      <td>YUM YUM # 28E ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>10.56</td>\n",
       "      <td>AMAZON.COM*MK4BR1VP2 AMZN.COM/BILLWA39CJ3SEW3JH</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   price                                             desc  \\\n",
       "1250 2020-09-18  119.65                    RALPHS #0021 SOUTH PASADEN CA   \n",
       "1251 2020-09-21    8.97                      VONS #3075 SOUTH PASADEN CA   \n",
       "1252 2020-09-23  643.44           PAYPAL *ACERRECER EBAY 888-221-1161 CA   \n",
       "1253 2020-09-23   44.09                       NAKEDWINES.COM INC NAPA CA   \n",
       "1254 2020-09-23   36.85                  WIPERBLADESUSA.COM HILLSBORO OR   \n",
       "1255 2020-09-24   12.46                eBay O*12-05780-94016 San Jose CA   \n",
       "1256 2020-09-29   13.48              BRISTOL FARMS # 02 SOUTH PASADEN CA   \n",
       "1257 2020-09-29   27.14                 CHEVRON 0308292 SOUTH PASADEN CA   \n",
       "1258 2020-09-29    6.07                      VONS #3075 SOUTH PASADEN CA   \n",
       "1259 2020-10-01    7.49                        YUM YUM # 28E ALHAMBRA CA   \n",
       "1260 2020-10-08   10.56  AMAZON.COM*MK4BR1VP2 AMZN.COM/BILLWA39CJ3SEW3JH   \n",
       "\n",
       "                card          cat st close st open Category  \n",
       "1250      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1251      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1252  discover -1362  Merchandise      NaT     NaT      NaN  \n",
       "1253      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1254      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1255      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1256      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1257      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1258      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1259      citi -6845          NaN      NaT     NaT      NaN  \n",
       "1260  discover -1362  Merchandise      NaT     NaT      NaN  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to cross reference against your cc hist sheet last entries\n",
    "full_cc_hist.loc[(max(full_cc_hist.index)-10) : max(full_cc_hist.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff, files_processed, cleaned_new_cc_info = all_things_to_add(hist_files, full_cc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff.to_csv(filepath + '/new_stuff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP:\n",
    "## open the new_stuff.csv, your non-updated cc_hist_tidy, and each extended purchase history csv you just downloaded for each card\n",
    "\n",
    "## find the last entry in the cc_hist for each card, find this on the purchase history and determine what you expect to see for that card in the new_stuff. Is new_stuff correct? If so, you good, otherwise, diagnose and treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think this was here to assist with checking new_stuff but I have everything i need already done (see above)\n",
    "\n",
    "# for card_cleaned in cleaned_new_cc_info:\n",
    "#     card_cleaned.to_csv(filepath + '/{}.csv'.format(card_cleaned['card'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\n",
      "You may now delete files ['C:/Users/geeze/Documents/finances/cc\\\\chase_2020YTD.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\citi_2020Year to date.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\discover-2020-YearToDateSummary.csv']\n",
      "they have been processed and added to the cc hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "      <th>Memo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>4.79</td>\n",
       "      <td>//USC Income (2,000/mo). Open date unknown</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>259.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>2013-12-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>343.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-02-24</td>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>237.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-03-27</td>\n",
       "      <td>2014-02-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>288.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-25</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>11.50</td>\n",
       "      <td>ELITE CLEANERS - SOUTH SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>8.27</td>\n",
       "      <td>VONS #3075 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>10.00</td>\n",
       "      <td>PAYPAL *POINSETTIA CEN 4029357733 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>18.57</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>28.03</td>\n",
       "      <td>99 CENTS ONLY STORES # ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1288 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   price                                        desc  \\\n",
       "0    2013-12-01    4.79  //USC Income (2,000/mo). Open date unknown   \n",
       "1    2014-01-01  259.39                                         NaN   \n",
       "2    2014-02-01  343.67                                         NaN   \n",
       "3    2014-03-01  237.71                                         NaN   \n",
       "4    2014-04-01  288.67                                         NaN   \n",
       "...         ...     ...                                         ...   \n",
       "1283 2020-11-25   11.50     ELITE CLEANERS - SOUTH SOUTH PASADEN CA   \n",
       "1284 2020-11-25    8.27                 VONS #3075 SOUTH PASADEN CA   \n",
       "1285 2020-11-30   10.00        PAYPAL *POINSETTIA CEN 4029357733 CA   \n",
       "1286 2020-11-30   18.57               RALPHS #0021 SOUTH PASADEN CA   \n",
       "1287 2020-11-30   28.03          99 CENTS ONLY STORES # ALHAMBRA CA   \n",
       "\n",
       "            card  cat   st close    st open Category  Memo  \n",
       "0     amex -2002  NaN 2013-12-27 2013-12-01      NaN   NaN  \n",
       "1     amex -2002  NaN 2014-01-27 2013-12-28      NaN   NaN  \n",
       "2     amex -2002  NaN 2014-02-24 2014-01-28      NaN   NaN  \n",
       "3     amex -2002  NaN 2014-03-27 2014-02-25      NaN   NaN  \n",
       "4     amex -2002  NaN 2014-04-25 2014-03-28      NaN   NaN  \n",
       "...          ...  ...        ...        ...      ...   ...  \n",
       "1283  citi -6845  NaN        NaT        NaT      NaN   NaN  \n",
       "1284  citi -6845  NaN        NaT        NaT      NaN   NaN  \n",
       "1285  citi -6845  NaN        NaT        NaT      NaN   NaN  \n",
       "1286  citi -6845  NaN        NaT        NaT      NaN   NaN  \n",
       "1287  citi -6845  NaN        NaT        NaT      NaN   NaN  \n",
       "\n",
       "[1288 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_new_cc_hist (full_cc_hist, new_stuff, filepath, files_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
