{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is the function you'll use to add an arbitrary cc table to your running cc history\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import datetime\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## general i/o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtime (string):\n",
    "    \"\"\"\n",
    "    converts strings to datetime objects using datetime.strptime mostly just wrote this so I could .apply() it in pandas\n",
    "    method chains\n",
    "    \n",
    "    takes (string) which is the full date of format mm/dd/yyyy (can't be 2 digit year)\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(string, '%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_full_hist (filepath):\n",
    "    \n",
    "    #full cc hist to update\n",
    "    full_cc_hist = pd.read_csv(filepath)\n",
    "    full_cc_hist['date'] = full_cc_hist['date'].apply(get_dtime)\n",
    "    \n",
    "    return full_cc_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chase_addendum (glob_list_of_cc_addenda):\n",
    "    \n",
    "    chase_file = [z for z in glob_list_of_cc_addenda if 'chase' in z][0]\n",
    "    \n",
    "    chase = pd.read_csv(chase_file)\n",
    "    \n",
    "    chase_clean = (chase.drop(['Type', 'Post Date'], axis=1)\n",
    "                   #chase updated \"Trans Date\" to \"Transaction Date\" on 2019-03-05\n",
    "               .rename(columns = {'Transaction Date' : 'date', 'Description' : 'desc', 'Amount' : 'price'})\n",
    "               .assign(card = 'chase -8723')\n",
    "              )\n",
    "    \n",
    "    chase_clean['price'] = chase_clean['price'].apply(np.negative)\n",
    "    chase_clean['date'] = chase_clean['date'].apply(get_dtime)\n",
    "    \n",
    "    ii = chase_clean['desc'].str.contains('AUTOMATIC PAYM')\n",
    "    chase_clean.loc[ii, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "#     min_max_dates = [min(chase_clean['date']), max(chase_clean['date'])]\n",
    "    \n",
    "    \n",
    "    return chase_clean, chase_file#, min_max_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comma (entry):\n",
    "    #if the entry is NOT a null (nan)\n",
    "    if not pd.isnull(entry):\n",
    "\n",
    "        if ',' in entry:\n",
    "            \n",
    "            entry = entry.replace(',', '')\n",
    "\n",
    "    return entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_price (df):\n",
    "     \n",
    "    #work with the credit info\n",
    "    cre = df['Credit']\n",
    "    \n",
    "    #where to flip credit to negative debit\n",
    "    i = cre.dropna().index\n",
    "    \n",
    "        #removed the addition of '-' to the Credits because the statements actually add the negative for me already\n",
    "        #as of 2019-03-05\n",
    "    df.loc[i, 'Debit'] = df.loc[i, 'Credit'].astype(str).apply(strip_comma)\n",
    "    \n",
    "    #rename for consistent column names\n",
    "    df = df.rename(columns = {'Debit' : 'price'})\n",
    "    \n",
    "    #get rid of commas\n",
    "    df['price'] = df['price'].astype(str).apply(strip_comma).astype(float)\n",
    "\n",
    "    df = df.drop('Credit', axis='columns')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_date_desc (df):\n",
    "    \n",
    "    #using get_dtime from chase munge\n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['desc'] = df['desc'].str.split('\\n', expand=True)[0]\n",
    "    \n",
    "    df.loc[df['desc'].str.contains('AUTOPAY'), 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citi_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'citi' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = make_price(df)\n",
    "    \n",
    "    df = df.rename(columns = {'Description' : 'desc', 'Date' : 'date'}).drop('Status', axis = 'columns')\n",
    "    \n",
    "    df = fix_date_desc(df)\n",
    "    \n",
    "    df['card'] = 'citi -6845'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_cols (df):\n",
    "    \n",
    "    return (df.rename(columns = {'Trans. Date' : 'date', 'Description' : 'desc', 'Amount' : 'price', 'Category' : 'cat'})\n",
    "            .drop('Post Date', axis='columns')\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_autopay (df):\n",
    "    \n",
    "    i = df['desc'].str.contains('DIRECTPAY')\n",
    "    \n",
    "    df.loc[i, 'desc'] = 'AUTOMATIC PAYMENT - THANK YOU'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_addendum (hist_files):\n",
    "    \n",
    "    file = [z for z in hist_files if 'discover' in z][0]\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    df = standard_cols(df)\n",
    "    \n",
    "    df = replace_autopay(df)\n",
    "    \n",
    "    df['date'] = df['date'].apply(get_dtime)\n",
    "    \n",
    "    df['card'] = 'discover -1362'\n",
    "    \n",
    "    return df, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_entries (full_cc_hist, clean_new_entries, card_name):\n",
    "    \"\"\"\n",
    "    Takes a properly column titled and formatted df of possible new entries\n",
    "    and takes all new entries after the last recorded transaction in the history,\n",
    "    returning these as a df\n",
    "    \"\"\"\n",
    "    \n",
    "    #get this card's transactions\n",
    "    card_idx = full_cc_hist['card'] == card_name\n",
    "\n",
    "    #get the date of the last recorded transaction on this card in the history\n",
    "    last_recorded_trans_date = max(full_cc_hist.loc[card_idx, 'date'])\n",
    "    \n",
    "\n",
    "    #get all downloaded transactions that happened AFTER the last recorded transaction date\n",
    "    #this assumed no retroactively applied transactions\n",
    "    eligible_new_trans = clean_new_entries.loc[clean_new_entries['date'] >= last_recorded_trans_date]\n",
    "    \n",
    "\n",
    "    #get the transactions from the full hist that occured on the last recorded date\n",
    "    #some of these may be repeated in the new entries, but some new entries may be new from that date\n",
    "    last_recorded_trans = full_cc_hist.loc[(full_cc_hist['date'] == last_recorded_trans_date) & card_idx]\n",
    "\n",
    "    #only possible overlaps here are ON the latest recorded transaction day, so put\n",
    "    #the new, and existing transactions from that day, together and remove duplicates\n",
    "    possible_overlap = pd.concat([eligible_new_trans, last_recorded_trans], sort=False)\n",
    "    \n",
    "\n",
    "    new_entries_idx = ~possible_overlap.duplicated(['date', 'price', 'card'], keep=False)\n",
    "    \n",
    "    #adding this block because a unique (not duplicated) last_recorded_trans will show up as a new transaction\n",
    "    #thanks to the concat step above followed by NOT dropping it again with the indexing below\n",
    "    #if it is not duplicated in the new entries, it is just ignored in the if part of this if/else\n",
    "    if all(new_entries_idx): #this means NONE of the eligible new transactions are duplicates of something in the last recorded transactions\n",
    "        new_entries = eligible_new_trans\n",
    "    else: #this means there were duplicates, both/all of which will be dropped\n",
    "        new_entries = possible_overlap.loc[new_entries_idx]\n",
    "    \n",
    "    return new_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_things_to_add (hist_files, full_cc_hist):\n",
    "    \n",
    "    #get the properly formatted chase transactions to be added and the date range they span\n",
    "    chase_clean, chase_file = get_chase_addendum(hist_files)\n",
    "    new_chase = find_new_entries (full_cc_hist, chase_clean, 'chase -8723')\n",
    "#     print('CHASE', new_chase)\n",
    "    \n",
    "    citi_clean, citi_file = get_citi_addendum(hist_files)\n",
    "    new_citi = find_new_entries (full_cc_hist, citi_clean, 'citi -6845')\n",
    "#     print('CITI', new_citi)\n",
    "    \n",
    "    disc_clean, disc_file = get_disc_addendum(hist_files)\n",
    "    new_disc = find_new_entries (full_cc_hist, disc_clean, 'discover -1362')\n",
    "#     print('DISC', new_disc)\n",
    "    \n",
    "    return pd.concat([new_chase, new_citi, new_disc], sort=False), [chase_file, citi_file, disc_file], [chase_clean, citi_clean, disc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_new_cc_hist (full_cc_hist, all_new_entries, file_dir, files_processed):\n",
    "    \n",
    "    new = (pd.concat([full_cc_hist, all_new_entries], sort=False)\n",
    "           .sort_values(by='date')\n",
    "           .reset_index(drop=True)\n",
    "          )\n",
    "    \n",
    "    #this requires that the cc history is in the same place as the files with new entries and has the name\n",
    "    # 'cc_hist_tidy'\n",
    "    new.to_csv(file_dir + '/cc_hist_tidy' + '.csv', index=False)\n",
    "    \n",
    "    print(\"The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\")\n",
    "    print(\"You may now delete files {}\".format(files_processed))\n",
    "    print(\"they have been processed and added to the cc hist\")\n",
    "    \n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/geeze/Documents/finances/cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_files = glob.glob(filepath + '/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/geeze/Documents/finances/cc\\\\cc_hist_tidy.csv',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20180205_20200205_20200205.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\citi_From 4_1_2019 To 2_5_2020.CSV',\n",
       " 'C:/Users/geeze/Documents/finances/cc\\\\discover-Last12Months-20200205.csv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#are these the right files?\n",
    "hist_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full cc hist to update\n",
    "full_cc_hist = open_full_hist([z for z in hist_files if 'tidy' in z][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>1.75</td>\n",
       "      <td>LA METRO UNION STATQPS LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2019-12-21</td>\n",
       "      <td>5.26</td>\n",
       "      <td>AMZN MKTP US*XO95N5603 AMZN.COM/BILLWALA7FDM4ZJJD</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Merchandise</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>3.64</td>\n",
       "      <td>CVS/PHARMACY #09668 PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>76.00</td>\n",
       "      <td>AMTRAK .3570721581493 8008727245 DC</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>15.88</td>\n",
       "      <td>UBER TECHNOLOGIES INC 8005928996 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>6.79</td>\n",
       "      <td>NINTENDO *AMERICAUS 800-255-3700 WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>89.72</td>\n",
       "      <td>AIRBNB HM4MJPKFJY 4158005959 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>28.64</td>\n",
       "      <td>CHEVRON 0211882 MILPITAS CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>28.81</td>\n",
       "      <td>CHEVRON 0308292 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>25.30</td>\n",
       "      <td>SANTA FE FOODS GONZALES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>70.18</td>\n",
       "      <td>DONA OAKLAND CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  price                                               desc  \\\n",
       "1084 2019-12-21   1.75              LA METRO UNION STATQPS LOS ANGELES CA   \n",
       "1085 2019-12-21   5.26  AMZN MKTP US*XO95N5603 AMZN.COM/BILLWALA7FDM4ZJJD   \n",
       "1086 2019-12-23   3.64                    CVS/PHARMACY #09668 PASADENA CA   \n",
       "1087 2019-12-23  76.00                AMTRAK .3570721581493 8008727245 DC   \n",
       "1088 2019-12-24  15.88                UBER TECHNOLOGIES INC 8005928996 CA   \n",
       "1089 2019-12-27   6.79                NINTENDO *AMERICAUS 800-255-3700 WA   \n",
       "1090 2019-12-27  89.72                    AIRBNB HM4MJPKFJY 4158005959 CA   \n",
       "1091 2019-12-29  28.64                        CHEVRON 0211882 MILPITAS CA   \n",
       "1092 2019-12-29  28.81                   CHEVRON 0308292 SOUTH PASADEN CA   \n",
       "1093 2019-12-29  25.30                         SANTA FE FOODS GONZALES CA   \n",
       "1094 2019-12-30  70.18                                    DONA OAKLAND CA   \n",
       "\n",
       "                card          cat st close st open Category  \n",
       "1084      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1085  discover -1362  Merchandise      NaN     NaN      NaN  \n",
       "1086      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1087      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1088      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1089      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1090      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1091      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1092      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1093      citi -6845          NaN      NaN     NaN      NaN  \n",
       "1094      citi -6845          NaN      NaN     NaN      NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to cross reference against your cc hist sheet last entries\n",
    "full_cc_hist.loc[(max(full_cc_hist.index)-10) : max(full_cc_hist.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff, files_processed, cleaned_new_cc_info = all_things_to_add(hist_files, full_cc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stuff.to_csv(filepath + '/new_stuff.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP:\n",
    "## open the new_stuff.csv, your non-updated cc_hist_tidy, and each extended purchase history csv you just downloaded for each card\n",
    "\n",
    "## find the last entry in the cc_hist for each card, find this on the purchase history and determine what you expect to see for that card in the new_stuff. Is new_stuff correct? If so, you good, otherwise, diagnose and treat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think this was here to assist with checking new_stuff but I have everything i need already done (see above)\n",
    "\n",
    "# for card_cleaned in cleaned_new_cc_info:\n",
    "#     card_cleaned.to_csv(filepath + '/{}.csv'.format(card_cleaned['card'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The updated history of cc transactions has been saved to file 'cc_hist_tidy.csv'. You're all done!\n",
      "You may now delete files ['C:/Users/geeze/Documents/finances/cc\\\\chase8723_Activity20180205_20200205_20200205.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\citi_From 4_1_2019 To 2_5_2020.CSV', 'C:/Users/geeze/Documents/finances/cc\\\\discover-Last12Months-20200205.csv']\n",
      "they have been processed and added to the cc hist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>desc</th>\n",
       "      <th>card</th>\n",
       "      <th>cat</th>\n",
       "      <th>st close</th>\n",
       "      <th>st open</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01</td>\n",
       "      <td>4.79</td>\n",
       "      <td>//USC Income (2,000/mo). Open date unknown</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2013</td>\n",
       "      <td>12/1/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>259.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2014</td>\n",
       "      <td>12/28/2013</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>343.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2014</td>\n",
       "      <td>1/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>237.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2014</td>\n",
       "      <td>2/25/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>288.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/25/2014</td>\n",
       "      <td>3/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>182.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2014</td>\n",
       "      <td>4/26/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>475.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/26/2014</td>\n",
       "      <td>5/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>326.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2014</td>\n",
       "      <td>6/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-08-01</td>\n",
       "      <td>346.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2014</td>\n",
       "      <td>7/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>164.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/26/2014</td>\n",
       "      <td>8/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>307.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2014</td>\n",
       "      <td>9/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-11-01</td>\n",
       "      <td>265.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/26/2014</td>\n",
       "      <td>10/28/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>424.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/26/2014</td>\n",
       "      <td>11/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>492.27</td>\n",
       "      <td>(bought LIB)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2015</td>\n",
       "      <td>12/27/2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>205.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/24/2015</td>\n",
       "      <td>1/28/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>310.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>584.24</td>\n",
       "      <td>(bought kaplan)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>3/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>521.30</td>\n",
       "      <td>(bought Uworld)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>4/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>184.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>5/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>324.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>6/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>494.87</td>\n",
       "      <td>(bought maggy maid, was paid back by roomates)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>7/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>224.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>8/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>428.84</td>\n",
       "      <td>//Begin Caltech Income (2,666.67/mo)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>9/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>363.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>10/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>345.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>11/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>573.70</td>\n",
       "      <td>(also bought computer, but reimbursed 894.94)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>12/27/2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>407.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>1/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>611.88</td>\n",
       "      <td>(bought LIB tix)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>2/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>864.00</td>\n",
       "      <td>(bought airline tix to PA and SEA)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>3/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>413.02</td>\n",
       "      <td>(bought stuff for SEA trip with grace)</td>\n",
       "      <td>amex -2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>4/27/2016</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>28.64</td>\n",
       "      <td>CHEVRON 0211882 MILPITAS CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>28.81</td>\n",
       "      <td>CHEVRON 0308292 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>70.18</td>\n",
       "      <td>DONA OAKLAND CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>30.96</td>\n",
       "      <td>CHEVRON 0209042 SAN MIGUEL CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>11.04</td>\n",
       "      <td>UBER TECHNOLOGIES INC 8005928996 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>54.08</td>\n",
       "      <td>VONS #3075 SOUTH PASADENCA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Supermarkets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>90.55</td>\n",
       "      <td>TRITONMAN 2020 3057109357 FL</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>15.00</td>\n",
       "      <td>USA TRIATHLON 7195979090 CO</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>3.15</td>\n",
       "      <td>EBAY INC. 866-779-3229 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>10.13</td>\n",
       "      <td>SQ *SQ *UNION BAKERY S PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>19.53</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.72</td>\n",
       "      <td>CITY PARKING METERS 626-7446454 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>-7.76</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>8.91</td>\n",
       "      <td>THE HOME DEPOT #6610 ALHAMBRA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>Amazon.com*I91DE7V03 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>28.44</td>\n",
       "      <td>Amazon.com*DU5ET4FP3 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>29.21</td>\n",
       "      <td>SHELL OIL 57444467807</td>\n",
       "      <td>chase -8723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>44.90</td>\n",
       "      <td>RALPHS #0021 SOUTH PASADENCA</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Supermarkets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>-1648.78</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>44.99</td>\n",
       "      <td>SPECTRUM 855-707-7328 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>6.50</td>\n",
       "      <td>LA CITY PARKING METER LOS ANGELES CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>-97.41</td>\n",
       "      <td>AUTOMATIC PAYMENT - THANK YOU</td>\n",
       "      <td>discover -1362</td>\n",
       "      <td>Payments and Credits</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>1769.14</td>\n",
       "      <td>gotogate_us L2GCTK Miami FL</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>14.18</td>\n",
       "      <td>FEDEX OFFIC57300005736 SOUTH PASADEN CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>8.75</td>\n",
       "      <td>AMZN Mktp US*J87QG98F3 Amzn.com/bill WA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>7.75</td>\n",
       "      <td>MAIL SERVICES PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>52.00</td>\n",
       "      <td>CITY CITATIONS &amp; PERMI 626-7444360 CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>8.60</td>\n",
       "      <td>DOG HAUS BIERGARDEN PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>46.18</td>\n",
       "      <td>VONS #3075 STH PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>9.89</td>\n",
       "      <td>KITCHEN UNITED INC PASADENA CA</td>\n",
       "      <td>citi -6845</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1122 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date    price                                            desc  \\\n",
       "0    2013-12-01     4.79      //USC Income (2,000/mo). Open date unknown   \n",
       "1    2014-01-01   259.39                                             NaN   \n",
       "2    2014-02-01   343.67                                             NaN   \n",
       "3    2014-03-01   237.71                                             NaN   \n",
       "4    2014-04-01   288.67                                             NaN   \n",
       "5    2014-05-01   182.03                                             NaN   \n",
       "6    2014-06-01   475.33                                             NaN   \n",
       "7    2014-07-01   326.33                                             NaN   \n",
       "8    2014-08-01   346.95                                             NaN   \n",
       "9    2014-09-01   164.56                                             NaN   \n",
       "10   2014-10-01   307.70                                             NaN   \n",
       "11   2014-11-01   265.87                                             NaN   \n",
       "12   2014-12-01   424.86                                             NaN   \n",
       "13   2015-01-01   492.27                                    (bought LIB)   \n",
       "14   2015-02-01   205.33                                             NaN   \n",
       "15   2015-03-01   310.22                                             NaN   \n",
       "16   2015-04-01   584.24                                 (bought kaplan)   \n",
       "17   2015-05-01   521.30                                 (bought Uworld)   \n",
       "18   2015-06-01   184.77                                             NaN   \n",
       "19   2015-07-01   324.40                                             NaN   \n",
       "20   2015-08-01   494.87  (bought maggy maid, was paid back by roomates)   \n",
       "21   2015-09-01   224.18                                             NaN   \n",
       "22   2015-10-01   428.84            //Begin Caltech Income (2,666.67/mo)   \n",
       "23   2015-11-01   363.99                                             NaN   \n",
       "24   2015-12-01   345.70                                             NaN   \n",
       "25   2016-01-01   573.70   (also bought computer, but reimbursed 894.94)   \n",
       "26   2016-02-01   407.37                                             NaN   \n",
       "27   2016-03-01   611.88                                (bought LIB tix)   \n",
       "28   2016-04-01   864.00              (bought airline tix to PA and SEA)   \n",
       "29   2016-05-01   413.02          (bought stuff for SEA trip with grace)   \n",
       "...         ...      ...                                             ...   \n",
       "1092 2019-12-29    28.64                     CHEVRON 0211882 MILPITAS CA   \n",
       "1093 2019-12-29    28.81                CHEVRON 0308292 SOUTH PASADEN CA   \n",
       "1094 2019-12-30    70.18                                 DONA OAKLAND CA   \n",
       "1095 2020-01-01    30.96                   CHEVRON 0209042 SAN MIGUEL CA   \n",
       "1096 2020-01-01    11.04             UBER TECHNOLOGIES INC 8005928996 CA   \n",
       "1097 2020-01-02    54.08                      VONS #3075 SOUTH PASADENCA   \n",
       "1098 2020-01-02    90.55                    TRITONMAN 2020 3057109357 FL   \n",
       "1099 2020-01-02    15.00                     USA TRIATHLON 7195979090 CO   \n",
       "1100 2020-01-03     3.15                       EBAY INC. 866-779-3229 CA   \n",
       "1101 2020-01-04    10.13              SQ *SQ *UNION BAKERY S PASADENA CA   \n",
       "1102 2020-01-05    19.53                THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1103 2020-01-05     0.72              CITY PARKING METERS 626-7446454 CA   \n",
       "1104 2020-01-06    -7.76                THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1105 2020-01-06     8.91                THE HOME DEPOT #6610 ALHAMBRA CA   \n",
       "1106 2020-01-08     3.41           Amazon.com*I91DE7V03 Amzn.com/bill WA   \n",
       "1107 2020-01-08    28.44           Amazon.com*DU5ET4FP3 Amzn.com/bill WA   \n",
       "1108 2020-01-11    29.21                           SHELL OIL 57444467807   \n",
       "1109 2020-01-12    44.90                    RALPHS #0021 SOUTH PASADENCA   \n",
       "1110 2020-01-12 -1648.78                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "1111 2020-01-13    44.99                        SPECTRUM 855-707-7328 CA   \n",
       "1112 2020-01-14     6.50            LA CITY PARKING METER LOS ANGELES CA   \n",
       "1113 2020-01-17   -97.41                   AUTOMATIC PAYMENT - THANK YOU   \n",
       "1114 2020-01-19  1769.14                     gotogate_us L2GCTK Miami FL   \n",
       "1115 2020-01-25    14.18         FEDEX OFFIC57300005736 SOUTH PASADEN CA   \n",
       "1116 2020-01-26     8.75         AMZN Mktp US*J87QG98F3 Amzn.com/bill WA   \n",
       "1117 2020-01-27     7.75                       MAIL SERVICES PASADENA CA   \n",
       "1118 2020-01-27    52.00           CITY CITATIONS & PERMI 626-7444360 CA   \n",
       "1119 2020-01-27     8.60                 DOG HAUS BIERGARDEN PASADENA CA   \n",
       "1120 2020-01-30    46.18                      VONS #3075 STH PASADENA CA   \n",
       "1121 2020-02-02     9.89                  KITCHEN UNITED INC PASADENA CA   \n",
       "\n",
       "                card                   cat    st close     st open Category  \n",
       "0         amex -2002                   NaN  12/27/2013   12/1/2013      NaN  \n",
       "1         amex -2002                   NaN   1/27/2014  12/28/2013      NaN  \n",
       "2         amex -2002                   NaN   2/24/2014   1/28/2014      NaN  \n",
       "3         amex -2002                   NaN   3/27/2014   2/25/2014      NaN  \n",
       "4         amex -2002                   NaN   4/25/2014   3/28/2014      NaN  \n",
       "5         amex -2002                   NaN   5/27/2014   4/26/2014      NaN  \n",
       "6         amex -2002                   NaN   6/26/2014   5/28/2014      NaN  \n",
       "7         amex -2002                   NaN   7/27/2014   6/27/2014      NaN  \n",
       "8         amex -2002                   NaN   8/27/2014   7/28/2014      NaN  \n",
       "9         amex -2002                   NaN   9/26/2014   8/28/2014      NaN  \n",
       "10        amex -2002                   NaN  10/27/2014   9/27/2014      NaN  \n",
       "11        amex -2002                   NaN  11/26/2014  10/28/2014      NaN  \n",
       "12        amex -2002                   NaN  12/26/2014  11/27/2014      NaN  \n",
       "13        amex -2002                   NaN   1/27/2015  12/27/2014      NaN  \n",
       "14        amex -2002                   NaN   2/24/2015   1/28/2015      NaN  \n",
       "15        amex -2002                   NaN   3/27/2015   2/25/2015      NaN  \n",
       "16        amex -2002                   NaN   4/27/2015   3/27/2015      NaN  \n",
       "17        amex -2002                   NaN   5/27/2015   4/27/2015      NaN  \n",
       "18        amex -2002                   NaN   6/27/2015   5/27/2015      NaN  \n",
       "19        amex -2002                   NaN   7/27/2015   6/27/2015      NaN  \n",
       "20        amex -2002                   NaN   8/27/2015   7/27/2015      NaN  \n",
       "21        amex -2002                   NaN   9/27/2015   8/27/2015      NaN  \n",
       "22        amex -2002                   NaN  10/27/2015   9/27/2015      NaN  \n",
       "23        amex -2002                   NaN  11/27/2015  10/27/2015      NaN  \n",
       "24        amex -2002                   NaN  12/27/2015  11/27/2015      NaN  \n",
       "25        amex -2002                   NaN   1/27/2016  12/27/2015      NaN  \n",
       "26        amex -2002                   NaN   2/27/2016   1/27/2016      NaN  \n",
       "27        amex -2002                   NaN   3/27/2016   2/27/2016      NaN  \n",
       "28        amex -2002                   NaN   4/27/2016   3/27/2016      NaN  \n",
       "29        amex -2002                   NaN   5/27/2016   4/27/2016      NaN  \n",
       "...              ...                   ...         ...         ...      ...  \n",
       "1092      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1093      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1094      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1095      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1096      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1097  discover -1362          Supermarkets         NaN         NaN      NaN  \n",
       "1098      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1099      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1100      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1101      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1102      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1103      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1104      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1105      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1106      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1107      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1108     chase -8723                   NaN         NaN         NaN      Gas  \n",
       "1109  discover -1362          Supermarkets         NaN         NaN      NaN  \n",
       "1110      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1111      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1112      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1113  discover -1362  Payments and Credits         NaN         NaN      NaN  \n",
       "1114      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1115      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1116      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1117      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1118      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1119      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1120      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "1121      citi -6845                   NaN         NaN         NaN      NaN  \n",
       "\n",
       "[1122 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_new_cc_hist (full_cc_hist, new_stuff, filepath, files_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
