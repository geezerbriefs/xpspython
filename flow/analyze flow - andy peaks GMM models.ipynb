{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import bisect\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.signal as signal\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting things\n",
    "\n",
    "#%matplotlib qt5 -- I don't know what this is\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from cycler import cycler\n",
    "\n",
    "\n",
    "#All of Anandh's customized seaborn/matplotlib settings\n",
    "\n",
    "sns.set_context(\"talk\", font_scale=1.5, rc={\"lines.linewidth\": 1.5})\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_style({\"xtick.direction\": \"in\",\"ytick.direction\": \"in\"})\n",
    "\n",
    "#%config InlineBackend.figure_f.ormats=['svg']\n",
    "\n",
    "mpl.rc('axes', prop_cycle=(cycler('color', ['r', 'k', 'b','g','y','m','c']) ))\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "#mpl.rc('text', usetex=False)\n",
    "#mpl.rc('text.latex', preamble=r'\\usepackage{helvet}\n",
    "#\\renewcommand\\familydefault{\\sfdefault}\\usepackage{sansmath}\\sansmath')\n",
    "\n",
    "    #If you want to use a different font\n",
    "# mpl.rc('font',**{'family':'sans-serif','sans-serif':['Helvetica'], \n",
    "#                  'serif': ['Helvetica']})\n",
    "\n",
    "tw = 1.5\n",
    "sns.set_style({\"xtick.major.size\": 3, \"ytick.major.size\": 3,\n",
    "               \"xtick.minor.size\": 2, \"ytick.minor.size\": 2,\n",
    "               'axes.labelsize': 16, 'axes.titlesize': 16,\n",
    "               'xtick.major.width': tw, 'xtick.minor.width': tw,\n",
    "               'ytick.major.width': tw, 'ytick.minor.width': tw})\n",
    "\n",
    "mpl.rc('xtick', labelsize=14) \n",
    "mpl.rc('ytick', labelsize=14)\n",
    "mpl.rc('axes', linewidth=1.5)\n",
    "mpl.rc('legend', fontsize=14)\n",
    "mpl.rc('figure', figsize=(9,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(file_directory, channel='GFP/FITC-A'):\n",
    "    ''' Reads in the values from a specific channel for a given flow file.\n",
    "    Defaults to taking GFP/FITC-A.'''\n",
    "    flow_data = pd.read_csv(file_directory)\n",
    "    flow_data_gfp_values = np.log10(flow_data[channel].values)\n",
    "    \n",
    "    return flow_data_gfp_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(file_directory, channel='GFP/FITC-A'):\n",
    "    '''Creates a dataframe from the given file directory. Reads in all csvs, \n",
    "    extracts the data from the channel of interest (defaults to GFP/FITC-A), \n",
    "    and returns one dataframe.'''\n",
    "    all_files = glob.glob(file_directory)\n",
    "    all_files.sort()\n",
    "    \n",
    "    all_data = []\n",
    "    for file in all_files:\n",
    "        data = get_values(file, channel)\n",
    "        all_data.append(data)\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(0, len(all_files)):\n",
    "        #this won't get the well label right in the output df unless the file format is:\n",
    "        #'../../../..\\'(letter)(number).csv'\n",
    "        #the forward slash is from glob filenames. this can't handle 'gated_data' at the beginning of the filename\n",
    "        mini_label = str(all_files[i].split('/')[-1].split('\\\\')[1].split('.')[0])\n",
    "        #print(mini_label)\n",
    "        label = [mini_label]*len(all_data[i])\n",
    "        labels.append(label)\n",
    "    \n",
    "    flat_all_data = [item for sublist in all_data for item in sublist]\n",
    "    flat_labels = [item for sublist in labels for item in sublist]\n",
    "    \n",
    "    df = pd.DataFrame(dict(well=flat_labels, log10GFP=flat_all_data))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_locations_from_KDE_fit(data):\n",
    "    ''' Performs a KDE fit and then uses scipy.signal.find_peaks_cwt to get peaks.\n",
    "        The KDE bandwith parameter is critical, and 0.25 has worked well in the past.\n",
    "        If it feels like you are missing many peak calls, decrease the bandwith. If it feels\n",
    "        like you are having too many peak calls, increase the bandwith. \n",
    "        \n",
    "        Don't change the bandwith without good reason, it took awhile to decide on 0.25. '''\n",
    "    \n",
    "    kde = KernelDensity(bandwidth=0.25, kernel='gaussian')\n",
    "    kde.fit(data[:, None]);\n",
    "\n",
    "    x_range = np.linspace(0, 6, 1200)\n",
    "    kde_estimates = np.exp(kde.score_samples(x_range[:, None]))\n",
    "\n",
    "    #Use the SciPy function to get the KDE peaks\n",
    "    peaks = signal.find_peaks_cwt(kde_estimates, np.arange(30, 200), min_snr=1)\n",
    "\n",
    "    means_init = []\n",
    "    \n",
    "    for peak in peaks:\n",
    "        means_init.append(x_range[peak])\n",
    "    \n",
    "    return means_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GMM_KDE(data, peaks, threshold = 0.01): \n",
    "    \"\"\"Generate a Gaussian mixture model from the output\n",
    "    of a Gaussian Kernel Density Estimation. \n",
    "    Outputs the mean of the on peak, fraction on, mean of the off peak, \n",
    "    and fraction off. This version of the code assumes all cells not in the on peak are off!\n",
    "    This is obviously only a good assumption for uni/bimodal data. If you have multimodal data,\n",
    "    do not use this code.\"\"\"\n",
    "    \n",
    "    data = data.reshape(len(data), 1)\n",
    "\n",
    "    peaks = np.array(peaks).reshape(len(peaks), 1)\n",
    "    opt_gmm = GaussianMixture(n_components = len(peaks) , means_init = peaks).fit(data)  \n",
    "\n",
    "    labels = opt_gmm.predict(data)\n",
    "    labels = np.ravel(labels.reshape(len(labels), 1))\n",
    "\n",
    "    means = opt_gmm.means_\n",
    "    \n",
    "    #this df contains each measurement value and the gaussian it is associated with.\n",
    "    #you can use this to pull out the measurements that fall into the desired gaussian for gating.\n",
    "    df = pd.DataFrame({'fluor value': np.ravel(data), 'which_gaussian': labels})\n",
    "\n",
    "\n",
    "    #df.head(10)\n",
    "    counts = []\n",
    "    means = []\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(0, len(peaks)):\n",
    "        df_distro = df.loc[df['which_gaussian']==i]\n",
    "        counts.append(len(df_distro))\n",
    "        means.append(np.mean(df_distro['fluor value'].values))\n",
    "\n",
    "    print('peaks identified in the kde fit of data: ', peaks)\n",
    "    print('means of the gaussians the GMM optimized: ', means)\n",
    "    print('counts in each gaussian: ', counts)\n",
    "    total = len(df)\n",
    "    # print('total: ', total)\n",
    "\n",
    "    fractions = np.array(counts)/total\n",
    "    print('raw fractions of data in each gaussian: ', fractions)\n",
    "\n",
    "    ##Initializing corrected lists of means and fractions of subpopulations\n",
    "    GMM_accepted_means = []\n",
    "\n",
    "    GMM_corrected_fractions = []\n",
    "\n",
    "    for i in range(0, len(fractions)):\n",
    "        if fractions[i] > threshold: \n",
    "            GMM_accepted_means.append(means[i])\n",
    "            GMM_corrected_fractions.append(fractions[i])    \n",
    "\n",
    "    print('means of gaussians that contain fraction of data above thresh ({}): '.format(threshold), GMM_accepted_means)\n",
    "    print('fraction of data in above-thresh gaussians: ', GMM_corrected_fractions)\n",
    "\n",
    "    #uses the gaussian with the highest mean (the last one in the accepted means) as the ON gaussian\n",
    "    index_of_on = GMM_accepted_means.index(max(GMM_accepted_means))\n",
    "\n",
    "    #the threshold collects all the fractions that are above threshold, meaning its possible for the sum\n",
    "    #of the collected fractions to be less than 1. This is fine because this line tosses everything except\n",
    "    #the fraction of measurements in the ON gaussian and calculates the fraction in the OFF as 1-this, \n",
    "    #saying that any sub-threshold counts above this are OFF and everything below this is also OFF\n",
    "    fraction_of_highest_peak = GMM_corrected_fractions[index_of_on]\n",
    "\n",
    "    fraction_off = 1 - fraction_of_highest_peak\n",
    "\n",
    "#     print('fraction in highest gaussian: ', fraction_of_highest_peak)\n",
    "#     print('1 - fraction_in_highest_gaussian: ', fraction_off)\n",
    "\n",
    "    mean_of_highest_peak = GMM_accepted_means[index_of_on]\n",
    "\n",
    "    #because there can be many possible above-threshold means that are OFF (below the highest mean-ed gaussian (ON) )\n",
    "    #we want to come up with an appropriate summary statistic for their value. This can be their mean mean, weighted by\n",
    "    #the fraction of the data they represent\n",
    "    #This means we multiply the mean of each non-ON gaussian by the fraction of measurements in that gaussian, then\n",
    "    #take the average of these weighted values to get the weighted average value for all the non-ON data.\n",
    "    weighted_peak_means = []\n",
    "    fracs_to_use = []\n",
    "    for i in range(0, len(GMM_corrected_fractions)):\n",
    "        #if its the one corresponding to the highest gaussian, do nothing\n",
    "        if i == index_of_on:\n",
    "            pass\n",
    "        #otherwise, compute the weighted average using this gaussian's data too.\n",
    "        else: \n",
    "            #we retransform out of log space because avg of 2 and 3 in log is 2.5,\n",
    "            #but real average is scaled by log 10 and avg value is not 10**2.5\n",
    "            weighted_mean = GMM_corrected_fractions[i] * np.power(10, GMM_accepted_means[i])\n",
    "            fracs_to_use.append(GMM_corrected_fractions[i])\n",
    "            weighted_peak_means.append(weighted_mean)\n",
    "            \n",
    "\n",
    "    mean_of_off_population = np.log10(np.sum(weighted_peak_means)/np.sum(fracs_to_use))\n",
    "\n",
    "    return mean_of_highest_peak, fraction_of_highest_peak, mean_of_off_population, fraction_off, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_GMM_KDE_wrapper (data):\n",
    "    \"\"\"Wrapper function to get both the peaks from a KDE fit, and then \n",
    "    from the Gaussian mixture model. Returns the mean of the broken cells, \n",
    "    and the fraction of broken cells.\"\"\"\n",
    "    \n",
    "    peak_locations= get_peak_locations_from_KDE_fit(data)\n",
    "    \n",
    "    mean_of_highest_peak, fraction_of_highest_peak, \\\n",
    "        mean_of_off_population, fraction_off, \\\n",
    "        df_gaussian_distros = fit_GMM_KDE(data, peak_locations, threshold = 0.01)\n",
    "    \n",
    "    return mean_of_highest_peak, fraction_of_highest_peak, mean_of_off_population, fraction_off, df_gaussian_distros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_method(df_, wells):\n",
    "    '''Wrapper function for the the entire generation of the final output df. \n",
    "    Takes the input dataframe and a list of all wells you want to perform GMM fitting on.\n",
    "    '''\n",
    "    means_on = []\n",
    "    fractions_on = []\n",
    "    means_off = []\n",
    "    fractions_off = []\n",
    "    wells_df = []\n",
    "    dfs_gaussian_distros = []\n",
    "    \n",
    "    for well in wells:\n",
    "        data = df_.loc[df_['well'] == well]\n",
    "        \n",
    "        YFP = data['log10GFP'].values\n",
    "        \n",
    "        mean_of_highest_peak, fraction_of_highest_peak, mean_of_off_population, \\\n",
    "                        fraction_off, df_gaussian_distros = fit_GMM_KDE_wrapper(YFP)\n",
    "        \n",
    "        means_on.append(mean_of_highest_peak)\n",
    "        fractions_on.append(fraction_of_highest_peak)\n",
    "        means_off.append(mean_of_off_population)\n",
    "        fractions_off.append(fraction_off)\n",
    "        dfs_gaussian_distros.append(df_gaussian_distros)\n",
    "        wells_df.append(well) \n",
    "\n",
    "    plt_df = pd.DataFrame({'mean ON': means_on, 'fraction ON' : fractions_on,\n",
    "                           'mean OFF':means_off, 'fraction OFF' : fractions_off,\n",
    "                           'well': wells_df, 'df_gaussian_distros': dfs_gaussian_distros})\n",
    "    \n",
    "    return plt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the list of wells that you have data files for and wish to fit with GMMs\n",
    "first = [i+j for i in ['A', 'B', 'C'] for j in ['1','2','3', '4', '5', '6', '7', '8', '9']]\n",
    "second = [i+j for i in ['D', 'E', 'F', 'G', 'H'] for j in ['1','2','3', '4', '5', '6', '7', '8']]\n",
    "\n",
    "wells_10 = first + second\n",
    "\n",
    "\n",
    "#all 96 wells\n",
    "wells = [i+j for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'] for j in ['1','2','3', '4', '5', '6', '7', '8', '9', '10', '11', '12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set some variables\n",
    "\n",
    "syto_channel = 'mKate/APC-A'\n",
    "yfp_channel = 'GFP/FITC-A'\n",
    "bfp_channel = 'CFP/VioBlue-A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geeze\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in log10\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Read in the tidied data generated by \"ADH_automatic_flow_gating_and_well_labeling.ipynb\"\n",
    "# The input for make_df is the directory that you want automatic fractions generated for. \n",
    "input_df = make_df('../../Local Data/20181009 top 4 A B cell vars A=B flow samples/23hr/[C][4].csv', channel=syto_channel)\n",
    "# print(input_df.shape)\n",
    "input_df = input_df.dropna()\n",
    "# print(input_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peaks identified in the kde fit of data:  [[0.235196  ]\n",
      " [3.71809842]]\n",
      "means of the gaussians the GMM optimized:  [1.7413081322762336, 3.5034089213006054]\n",
      "counts in each gaussian:  [113, 9268]\n",
      "raw fractions of data in each gaussian:  [0.01204562 0.98795438]\n",
      "means of gaussians that contain fraction of data above thresh (0.01):  [1.7413081322762336, 3.5034089213006054]\n",
      "fraction of data in above-thresh gaussians:  [0.012045624133887645, 0.9879543758661123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geeze\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    }
   ],
   "source": [
    "# Generate an output_df by running GMM method. The inputs are the input_df and\n",
    "# the list of all wells you want generated\n",
    "output_df = GMM_method(input_df, ['C4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean ON</th>\n",
       "      <th>fraction ON</th>\n",
       "      <th>mean OFF</th>\n",
       "      <th>fraction OFF</th>\n",
       "      <th>well</th>\n",
       "      <th>df_gaussian_distros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.503409</td>\n",
       "      <td>0.987954</td>\n",
       "      <td>1.741308</td>\n",
       "      <td>0.012046</td>\n",
       "      <td>C4</td>\n",
       "      <td>fluor value  which_gaussian\n",
       "0        1.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean ON  fraction ON  mean OFF  fraction OFF well  \\\n",
       "0  3.503409     0.987954  1.741308      0.012046   C4   \n",
       "\n",
       "                                 df_gaussian_distros  \n",
       "0        fluor value  which_gaussian\n",
       "0        1.7...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the output to make sure it looks correct\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the output file to a csv. \n",
    "output_df.to_csv('../../Local Data/20181009 top 4 A B cell vars A=B flow samples/23hr/C4_TEST.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
