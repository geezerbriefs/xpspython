{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#get all the files from your experiment\n",
    "import glob\n",
    "\n",
    "#deal with the .fcs file format\n",
    "import fcsparser\n",
    "\n",
    "#for writing info back to excel ID sheet\n",
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use glob to get all the fcs files you want to deal with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_assoc_to_xlsx (ids_frame_w_fnames, ids_xlsx_path):\n",
    "\n",
    "    #the check to see if the ids xlsx file already has filenames is done in the function that calls this one [assoc_fname_well]\n",
    "    \n",
    "    #open the workbook\n",
    "    book = openpyxl.load_workbook(ids_xlsx_path)\n",
    "\n",
    "    #get the worksheet you want to edit by name. Assumes standard sheet naming where single sheet in book is called 'Sheet1'\n",
    "    sheet = book[\"Sheet1\"]\n",
    "\n",
    "    #initialize row counter (because lazy)\n",
    "    r = 1\n",
    "    #set the file column name in row 1\n",
    "    sheet.cell(row=r, column=4).value = \"file\"\n",
    "\n",
    "    #loop over file dataframe column entries and assign to the xlsx in successive rows (r) in same column\n",
    "    for filename in ids_frame_w_fnames['file']:\n",
    "        #go to the next row\n",
    "        r += 1\n",
    "\n",
    "        #assign the values of successive cells in the col\n",
    "        sheet.cell(row=r, column=4).value = filename\n",
    "\n",
    "    #save it to same place so its overwritten with new good file\n",
    "    book.save(ids_xlsx_path)\n",
    "    \n",
    "    print (\"filename associations are written to the ids xlsx file\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assoc_fname_well (ids_frame, fcs_filename_list, ids_xlsx_path):\n",
    "\n",
    "    #make copy so you aren't editing the original id frame in the function\n",
    "    ids = ids_frame.copy()\n",
    "\n",
    "    #if the ids dataframe loaded from xlsx doesn't already have a \"file\" column with associated filenames\n",
    "    if 'file' not in ids.columns:\n",
    "\n",
    "        #add the filename to the IDs dataframe so you can look for well and get filename for analysis\n",
    "\n",
    "        #get the index and the fcs file num as a tuple.\n",
    "        #I'm pretty sure if the index was noncontinuous, this would still associate correct index to fcs num entry\n",
    "        for idx, num in zip(ids['fcs num'].index, ids['fcs num']):\n",
    "\n",
    "\n",
    "            #get the list of filenames that contain the fcs num you're looking for\n",
    "            #this list should ideally be len = 1\n",
    "            fname = [f for f in fcs_filename_list if num in f]\n",
    "\n",
    "            #this list that will be added to the 'file' column is sometimes just a string, sometimes a list with one element\n",
    "            #I want just the value inside the list\n",
    "            if len(fname) == 1:\n",
    "                add = fname[0]\n",
    "            elif len(fname) == 0:\n",
    "                add = 'NO MATCH'\n",
    "            elif len(fname) > 1:\n",
    "                add = '> 1 MATCH'\n",
    "\n",
    "\n",
    "            ids.loc[idx, 'file'] = add\n",
    "\n",
    "        \n",
    "        #check how the filename assignment went\n",
    "        \n",
    "        #if the value of these statements are TRUE, then there's a non-assignment or a multiple assignment of filenames\n",
    "        if any(ids['file'] == 'NO MATCH'):\n",
    "            print(\"there's a non-assignment of at least one well and filename!!!\")\n",
    "\n",
    "        elif any(ids['file'] == '> 1 MATCH'):\n",
    "            print(\"there's an assignment of multiple filenames to at least one well!!!\")\n",
    "\n",
    "        else:\n",
    "            print(\"assignment completed without issue, all wells have a single filaname assignment\")\n",
    "\n",
    "            \n",
    "        #write the new IDs frame with file associations to the original ids xlsx file\n",
    "        write_file_assoc_to_xlsx(ids, ids_xlsx_path)    \n",
    "        \n",
    "        #return the frame with the new filename associations\n",
    "        return ids\n",
    "\n",
    "    #if the ids dataframe already has the filename associations\n",
    "    else:\n",
    "        #do nothing\n",
    "        print (\"the id dataframe and its parent xlsx file already contain a column called 'file' that has the fcs filename associations, the id dataframe and its parent file have not been modified\")\n",
    "        #return it as is\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_dir = 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/'\n",
    "\n",
    "tpt = '18'\n",
    "\n",
    "\n",
    "dir_with_fcs_files_path = (upper_dir + tpt + '/' + 'raw/')\n",
    "\n",
    "#get all the .fcs files in the directory (doesn't walk down directories to aggregate all further along dir tree)\n",
    "allfcs = glob.glob(dir_with_fcs_files_path + '/*.fcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\bfp-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\blank-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\blankno-RDM2019-02-15.0001.fcs']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allfcs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the endings, which are the actual filenames, separate from the directory tree\n",
    "fnames = [x.split('\\\\')[1] for x in allfcs]\n",
    "\n",
    "#get the ones that don't have anything at the front, those are the experimental ones\n",
    "expnames = [x for x in fnames if x.startswith('RDM')]\n",
    "\n",
    "#re-attach the directory tree\n",
    "expfcs = [upper_dir+tpt+'/'+'raw\\\\'+x for x in expnames]\n",
    "\n",
    "\n",
    "#nicer way to use previous list to get ctrls out of allfcs\n",
    "\n",
    "ctrlfcs = [d for d in allfcs if d not in expfcs]\n",
    "\n",
    "finalctrlfcs = [f for f in ctrlfcs if 'final' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\bfp-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\blank-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\blankno-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\blch1-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\blch2-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\cal-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\di1-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\di2-RDM2019-02-15.0001.fcs',\n",
       " 'Z:/Reed/Projects/micro_consortia/DARPA_biocon/Task 1.1/A=B/20190214 A=B mar cfp yfp small screen 1/flow/18/raw\\\\yfp-RDM2019-02-15.0001.fcs']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrlfcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I created a csv file that correlates fcs file number to well and volume flowed\n",
    "ids_xlsx_path = dir_with_fcs_files_path + '/' + tpt + '-fcs num to well ID.xlsx'\n",
    "\n",
    "ids = pd.read_excel(ids_xlsx_path, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fcs num</th>\n",
       "      <th>well</th>\n",
       "      <th>vol</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>sampling_dil</th>\n",
       "      <th>flow_dil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>a1-BAD</td>\n",
       "      <td>25</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002</td>\n",
       "      <td>A1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003</td>\n",
       "      <td>B1</td>\n",
       "      <td>7</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004</td>\n",
       "      <td>C1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005</td>\n",
       "      <td>D1</td>\n",
       "      <td>15</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0006</td>\n",
       "      <td>E1</td>\n",
       "      <td>6</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0007</td>\n",
       "      <td>F1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0008</td>\n",
       "      <td>G1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0009</td>\n",
       "      <td>H1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0010</td>\n",
       "      <td>A2</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0011</td>\n",
       "      <td>B2</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fcs num    well vol Unnamed: 3 sampling_dil flow_dil\n",
       "0     0001  a1-BAD  25        nan          nan      nan\n",
       "1     0002      A1  10        nan            4       40\n",
       "2     0003      B1   7        nan            4       40\n",
       "3     0004      C1  10        nan            4       40\n",
       "4     0005      D1  15        nan            4       40\n",
       "5     0006      E1   6        nan            4       40\n",
       "6     0007      F1  10        nan            4       40\n",
       "7     0008      G1  10        nan            4       40\n",
       "8     0009      H1  10        nan            4       40\n",
       "9     0010      A2  10        nan            4       40\n",
       "10    0011      B2  10        nan            4       40"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assignment completed without issue, all wells have a single filaname assignment\n",
      "filename associations are written to the ids xlsx file\n"
     ]
    }
   ],
   "source": [
    "ids = assoc_fname_well (ids, expfcs, ids_xlsx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create some csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_from_fcs (desired_well, ids_frame):\n",
    "    \n",
    "    #get the index of the well you want in the ids frame\n",
    "    idx = ids_frame['well'] == desired_well\n",
    "    \n",
    "    #if the idx list is empty (no well matches), return None\n",
    "    if not any(idx):\n",
    "        return None\n",
    "    \n",
    "    #gotta get values, which is an array, hence the [0], to get the actual string inside the array\n",
    "    #because fcsparser only takes string input, can't deal with dataframe slices or arrays\n",
    "    path = ids_frame.loc[idx, 'file'].values[0]\n",
    "    \n",
    "    #use fcsparser to unpack fcs file to dataframe, get both the metadata and dataframe in case you want both\n",
    "    meta, data = fcsparser.parse(path, meta_data_only=False, reformat_meta=True)\n",
    "    \n",
    "    return meta, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_csv (well_data_dict, dir_to_save):\n",
    "    \n",
    "    for key in well_data_dict.keys():\n",
    "        #meta data stored in [0] of tuple, data in [1]\n",
    "        data = well_data_dict[key]\n",
    "        \n",
    "        #for entries that aren't matched\n",
    "        if data is None:\n",
    "            pass\n",
    "        #if it is a match\n",
    "        else:\n",
    "            data = data[1]\n",
    "            data.to_csv(dir_to_save + '/' + key + '.csv', index=False)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = [i+j for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'] for j in ['1','2','3', '4', '5', '6', '7', '8', '9', '10', '11', '12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data_dictionary = {well : get_dataframe_from_fcs(well, ids) for well in wells}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_csv(well_data_dictionary, dir_with_fcs_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
